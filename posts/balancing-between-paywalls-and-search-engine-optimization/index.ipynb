{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- metadata: title -->\n",
    "# Balancing between Paywalls and Search Engine Optimization\n",
    "\n",
    "<!-- metadata: subtitle -->\n",
    "> ### How Media Paywals Should work: A Research Case for Nation Media Group\n",
    "\n",
    "<!-- metadata: keywords, is_array=true -->\n",
    "**Keywords:**\n",
    "  - nation-media-group\n",
    "  - paywalls\n",
    "  - search-engine-optimization\n",
    "  - cloudflare\n",
    "\n",
    "<!-- metadata: categories, is_array=true -->\n",
    "**Categories:**\n",
    "  - cyber-security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:**\n",
    "<!-- metadata: disclaimer, strip_markdown=false -->\n",
    "Please note that this is meant for educational purposes only. You will be peronally liable for any misuse of the information provided here. We [contacted Nation Media Group](https://www.nationmedia.com/contact/) on Jun 3, 2024, 2:30â€¯PM East African Time, but they did not respond. ^[We [contacted Nation Media Group](https://www.nationmedia.com/contact/) through the following emails: <support@nation.africa>, <sales_inquiries@ke.nationmedia.com>, <newsdesk@ke.nationmedia.com>, <publiceditor@ke.nationmedia.com>, <mailbox@ke.nationmedia.com>, <epaper@ke.nationmedia.com>, <Customercare@ke.nationmedia.com>]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Nation Media Group logo](nation-media-group.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain independence of content creation, creators and authors need some form of monetization. For text content, one of the most common is advertizing. creators and authors can advertize directly or signup for services such as google adsense. Another form of monetization is publishing premium content that is initially only available to paid users. this is especially common for news media outlets because the most recent contents is usually the most relevant.\n",
    "\n",
    "However, for users to discover your content, they need to find it in search engines such as google or bing or duck duck go. For bet results, it makes sense to allow search engines to see the whole premium article to allow them to suggest it when users search for something similar. This is called search engine optimization. You might have the best news content, but if no one can find them, then its probably useless!\n",
    "\n",
    "The conflict to allow partial access to premium content while still restricting the content to unpaid users is a thin balance that most media house have to maintain. Users often find cleaver ways to circumnavigent the paywalls to see the paid content for free. There are online forums dedicated to discovering these vulnerabilities, such as \"[Bypassing Daily Nation Paywall](https://www.reddit.com/r/Kenya/comments/s96k01/bypassing_daily_nation_paywall/?rdt=48760)\" and \"[You can bypass most soft paywalls with a little CSS knowledge](https://www.reddit.com/r/educationalgifs/comments/lk1not/you_can_bypass_most_soft_paywalls_with_a_little/)\". The raw ideas shared in these forums often simple but require some basic programming skills to execute. In that sense, most people would prefer to just pay that learn how to execute the ideas.\n",
    "\n",
    "However, some users also create browser plugins that automatically do the heavy lifting for the user, allowing them to automatically view the premium content without any effort. Website Browser plugin stores and code repositories that contain plugins that allow paywall bypass are usually taken down and shut down, such as the famous <https://github.com/iamadamdev/bypass-paywalls-chrome>, but not before the code has found a new home, such as <https://github.com/nikolqyy/bypass-paywalls-chrome/releases/tag/most-recent> ^[https://news.ycombinator.com/item?id=41294166].\n",
    "\n",
    "As imagined, this is very time consuming, because you'd have to find out which plugins are currently available to bypass your paywalls. Also, it is not instant. it takes a while to execute a DMCA takedown notice. And even after its successful, someone who has a cloned repo will reupload the code and or plugin and the process continues. There is also a downside with the fact that this only affect publicly available plugins and ideas. Also, the more you try to control, the more it spreads that your website can be bypassed, thereby prompting users who used to happily pay feel like they have been short charged, and start looking for ways to bypass. This strategy also only tends to favor famous plugins and code repositories. The least known repositories are left to grow  because you dont know they exist (eg: <https://github.com/nikolqyy/bypass-paywalls-chrome>), and its very unlikely users who are used to access content for free are going to pay for it even if you disallow the access. there is also the fact that users who have already installed the pluggins will continue to enjoy the premium content without paying. \n",
    "\n",
    "## The Better Solution\n",
    "\n",
    "After a DMCA takedown notice, the most logical next thing is to change some aspects of your website such as class names and aragements of the site contents to make the old plugins not to work. but there is a slightly better solution, one that is scallable, cheap and doesnt compromise on search engine optimization.\n",
    "\n",
    "The solution involves keeping a select list of search engines allowing to read all the premium content for search engine optimization. These may include `google`, `bing`, `duckduckgo`, `yandex`, `baidu`, `yahoo` and `ahrefs`. In your web servers, you would check the ip address of the calling client and do a reverse DNS lookup to findout if the IP address is associated with the whitelisted search engines.\n",
    "\n",
    "This ofcourse is an expensive operation and should be optimized by caching the result for about a week. this means an IP adress that has been found to be associated with a search engine should not be re-evaluated again for about a week. this keeps a good balance between functionality and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nation Media Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic here affects <https://nation.africa/> and <https://www.businessdailyafrica.com/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial CSS-Based Paywall\n",
    "\n",
    "Initially, the Nation Media Group implemented a simple CSS-based paywall that could be easily bypassed with a few lines of JavaScript. This code simply removed paywall-related elements and classes, effectively granting free access to premium content.\n",
    "\n",
    "```js\n",
    "setTimeout(() => {\n",
    "    // https://nation.africa/\n",
    "    // Remove the paywall element\n",
    "    document.querySelector('.wall-guard')?.remove();\n",
    "    // Allow copying the text\n",
    "    document.querySelectorAll('.blk-txt')?.forEach(\n",
    "      i => i.classList.remove('blk-txt'));\n",
    "\n",
    "    // https://www.businessdailyafrica.com/\n",
    "    // Remove the paywall spinner\n",
    "    document.querySelector('.spinner')?.remove();\n",
    "    // Remove the paywall element\n",
    "    document.querySelector('.paywall')?.remove();\n",
    "    // Remove the call for action\n",
    "    document.querySelector('.grid-container-medium')?.remove();\n",
    "\n",
    "    // https://www.businessdailyafrica.com/ AND https://nation.africa/\n",
    "    // Show the hidden content\n",
    "    document.querySelectorAll('.paragraph-wrapper.nmgp')?.forEach(\n",
    "      i => i.classList.remove('nmgp'));\n",
    "}, 1);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced JavaScript Security Layer\n",
    "\n",
    "After reporting the issue to them, they added a javascript layer to prevent easy access to the premium content. They implemented a more sophisticated JavaScript-based security layer. However, this too could be bypassed with a more complex script. \n",
    "\n",
    "\n",
    "There is now a javascript code that runs to remove the actual content from the DOM, which means that CSS alone will not show the content.\n",
    "However, there is a way we can silently disable javascript, by refetching the html again and parsing the html text as DOM but without running javascript. this essentially allowes the old CSS method to continue working. \n",
    "\n",
    "This script fetches the original HTML, removes paywall elements, enables images, and replaces the entire body content, effectively bypassing the enhanced security measures.\n",
    "\n",
    "```js\n",
    "setTimeout(async () => {\n",
    "    // remove popup and make page scrollable\n",
    "    const removePopup = (maxRetries, retries) => {\n",
    "        setTimeout(() => {\n",
    "            const popUp = document.querySelector('.fc-ab-root')\n",
    "            if (popUp) {\n",
    "                popUp?.remove()\n",
    "                document.body.style = \"\"\n",
    "            } else if (retries < maxRetries) {\n",
    "                removePopup(maxRetries, retries + 1)\n",
    "            }\n",
    "        }, 300);\n",
    "    };\n",
    "    // re-fetch html from the current link\n",
    "    const htmlString = await fetch(location.href).then(resp => resp.text())\n",
    "    // parse the HTML without Javascript!\n",
    "    const newHtmlDocument = new DOMParser().parseFromString(htmlString, 'text/html');\n",
    "    // https://nation.africa/\n",
    "    // Remove the paywall element\n",
    "    newHtmlDocument.querySelector('.wall-guard')?.remove();\n",
    "    // Allow copying the text\n",
    "    newHtmlDocument.querySelectorAll('.blk-txt')?.forEach(i\n",
    "     => i.classList.remove('blk-txt'));\n",
    "\n",
    "    // https://www.businessdailyafrica.com/\n",
    "    // Remove the paywall spinner\n",
    "    newHtmlDocument.querySelector('.spinner')?.remove();\n",
    "    // Remove the paywall element\n",
    "    newHtmlDocument.querySelector('.paywall')?.remove();\n",
    "    // Remove the call for action\n",
    "    newHtmlDocument.querySelector('.grid-container-medium')?.remove();\n",
    "\n",
    "    // https://www.businessdailyafrica.com/ AND https://nation.africa/\n",
    "    // Show the hidden content\n",
    "    newHtmlDocument.querySelectorAll('.paragraph-wrapper.nmgp')?.forEach(\n",
    "      i => i.classList.remove('nmgp'));\n",
    "    // Enable images\n",
    "    newHtmlDocument.querySelectorAll('img.lazy-img').forEach(\n",
    "      i => i.classList.remove('lazy-img'))\n",
    "    newHtmlDocument.querySelectorAll('img[data-src]').forEach(img => {\n",
    "        const { dataset } = img;\n",
    "        img.src = dataset.src ?? img.src;\n",
    "        img.srcset = dataset.srcset ?? img.srcset;\n",
    "    });\n",
    "    // Remove spinners\n",
    "    newHtmlDocument.querySelectorAll('.spinner').forEach(i => i.remove());\n",
    "    // Remove cloundflare email protection label\n",
    "    newHtmlDocument.querySelector('.__cf_email__')?.closest('.paragraph-wrapper')?.remove();\n",
    "\n",
    "    document.body.outerHTML = newHtmlDocument.body.outerHTML;\n",
    "\n",
    "    removePopup(50, 0)\n",
    "}, 10);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate, you can use the article that was premium before june and is still premium now, such as <https://nation.africa/kenya/business/inside-world-bank-tough-terms-sh158bn-loan-kenya-4642634>. to access the old logic, use an archived version of the premium article at <https://web.archive.org/web/20240601075749/https://nation.africa/kenya/business/inside-world-bank-tough-terms-sh158bn-loan-kenya-4642634>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The appropriate Fix (`python code`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach would make it significantly more difficult to bypass the paywall while still allowing search engines to index the full content. However, it's worth noting that determined users could still potentially access the content by routing their requests through services like Google's PageSpeed Insights (https://pagespeed.web.dev/).\n",
    "\n",
    "**Implementation Considerations**\n",
    "\n",
    "To implement this solution effectively, consider the following:\n",
    "\n",
    "1. **Accurate IP Database**: Maintain an up-to-date database of IP ranges used by major search engines.\n",
    "2. **Performance Optimization**: Ensure that the IP lookup and content serving process is optimized to minimize latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from ipaddress import ip_address as parse_ip_address\n",
    "\n",
    "async def reverse_dns_lookup(ip_address: str, *host_names: tuple[str, ...]) -> bool:\n",
    "    \"\"\"\n",
    "    Perform reverse DNS lookup.\n",
    "    Usage example:\n",
    "        await reverse_dns_lookup(\"66.249.66.1\", \"googlebot.com\", \"google.com\")\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ip_address : str\n",
    "        the ip address of the client that called the server, \n",
    "        or the header value of \"X-Forwarded-For\" incase a \n",
    "        proxy/CDN such as cloudflare is used!\n",
    "    host_names : list[str]\n",
    "        allowed search engines\n",
    "        eg: \"googlebot.com\", \"search.msn.com\", \"duckduckgo.com\", etc\n",
    "\n",
    "    More Information:\n",
    "    Verifying Googlebot: \n",
    "        https://developers.google.com/search/docs/advanced/crawling/verifying-googlebot\n",
    "    How to access the sitemap.xml file of stackoverflow.com\n",
    "        https://meta.stackexchange.com/a/324471\n",
    "    Reverse IP Domain Check?\n",
    "        https://stackoverflow.com/a/716753/3563013\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(host_names) > 0:\n",
    "            # Raises `ValueError`if ip_address is not valid IPv4 or IPv6 address.\n",
    "            valid_ip_address: str = str(parse_ip_address(ip_address))\n",
    "            # Perform reverse DNS lookup\n",
    "            # Get hostname from IP, eg: ('crawl-66-249-66-1.googlebot.com', [], ['66.249.66.1'])\n",
    "            ip_address_hostname, aliases_1, _ = socket.gethostbyaddr(valid_ip_address)\n",
    "            # Get all IP addesses resolving the hostname (both IPv4 and IPv6)\n",
    "            ip_address_list = list(set(\n",
    "                [ip[4][0] for ip in socket.getaddrinfo(ip_address_hostname, None)]))\n",
    "            # Check if IP matches any of the addresses for the hostname\n",
    "            if valid_ip_address in ip_address_list:\n",
    "                # Perform forward DNS lookup to get all aliases\n",
    "                _, aliases_2, _ = socket.gethostbyname_ex(ip_address_hostname)\n",
    "                all_aliases = list(set([ip_address_hostname] + aliases_1 + aliases_2))\n",
    "                # Check if hostname or its aliases match any of the allowed hosts\n",
    "                return any(\n",
    "                    i for i in host_names \n",
    "                    if any(\n",
    "                        j for j in all_aliases \n",
    "                        if i.casefold().endswith(j.casefold()) \\\n",
    "                            or j.casefold().endswith(i.casefold())))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "await reverse_dns_lookup(\"66.249.66.1\", \"googlebot.com\", \"googleusercontent.com\", \"google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can tell, doing this for every request is resource intensive, and it is best to cache this for about 7 days. a verified ip address should be allowed to query for a week without firther checks for a week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good news for Nation Media group\n",
    "\n",
    "Since nation media group is already using Cloudflare for theor CDN, they dont even have to rewrite their server code. they can use an intermedially service from cloudflare called [web workers](https://workers.cloudflare.com/). This would allow them to intercept the requests from clients and implementnt the reverse DNS lookup using a webworker. webworkers provides first-class support for JavaScript, TypeScript, Python, Rust while supporting any programming language via [WebAssembly](https://developers.cloudflare.com/workers/runtime-apis/webassembly/). Regarding the cost, it free for the first `100k` requests each day, and just `$5` per `10 million` requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It's crucial to remember that no system is foolproof, and ongoing vigilance and updates are necessary to maintain the integrity of the paywall.\n",
    "As the digital media landscape continues to evolve, so too must the strategies for protecting and monetizing content. The proposed solution represents a step forward in this ongoing challenge, providing a more sophisticated approach to paywall implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
