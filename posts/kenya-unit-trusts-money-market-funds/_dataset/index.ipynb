{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- metadata: title -->\n",
    "# Collective Investment Schemes in Kenya: Money Market Funds(KES) - Analysis Dataset\n",
    "\n",
    "<!-- metadata: subtitle -->\n",
    "> ### Sourcing, Cleaning, and Exploratoring the Kenyan Money Market Fund Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Published Date:**\n",
    "<!-- metadata: date -->\n",
    "2024-09-25\n",
    "<!-- metadata: -->\n",
    "\n",
    "<!-- metadata: keywords, is_array=true -->\n",
    "**Keywords:**\n",
    "  - money\n",
    "  - kenya\n",
    "  - unit-trusts\n",
    "  - money-market-funds\n",
    "  - MMF\n",
    "  - dataset\n",
    "\n",
    "<!-- metadata: categories, is_array=true -->\n",
    "**Categories:**\n",
    "  - kenya unit trusts\n",
    "  - data science\n",
    "  - money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "<!-- metadata: description -->\n",
    "Money Market Funds (MMFs) are a type of collective investment scheme in Kenya that have gained significant popularity in recent years. These funds operate by pooling capital from numerous investors, which professional fund managers then invest collectively in short-term, highly liquid financial instruments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Kenyan financial landscape, MMFs offer several advantages over traditional bank deposits:\n",
    "\n",
    "1. Higher Returns: MMFs typically provide superior interest rates compared to standard savings accounts.\n",
    "2. Lower Entry Barriers: Investors can start with smaller amounts, making them more accessible to a broader range of investors.\n",
    "3. Compound Interest: Unlike most bank deposits that offer simple interest, MMFs generally provide compound interest, potentially leading to faster wealth accumulation.\n",
    "4. Liquidity: MMFs maintain high liquidity, allowing investors to access their funds quickly when needed, within a day or two after withdrawal.\n",
    "\n",
    "Our analysis will delve into the performance and characteristics of various Money Market Funds in Kenya, utilizing publicly available data. Through this exploration, we aim to:\n",
    "\n",
    "1. Source and gather data\n",
    "2. Clean the data and perform simple EDA\n",
    "3. Archive and publish the data for further and future analysis\n",
    "\n",
    "This analysis will not only offer basic insights into the current state of these investments but also contribute to a broader understanding of unit trust investments in the Kenyan financial market.\n",
    "\n",
    "Through our process of data sourcing, cleaning, and exploratory analysis, we aim to primarily enable researchers perform further analysis with the data, while also uncovering valuable insights that could benefit both potential investors and industry stakeholders in making informed decisions about Money Market Funds in Kenya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, lets prepapre our enviroment with some important python packages and reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show python imports\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root directory as python path\n",
    "root_dir = os.path.abspath(Path(sys.executable).parents[2])\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Other imports\n",
    "import pandas as pd\n",
    "from pyppeteer.page import Request, Page\n",
    "import asyncio\n",
    "import io\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from urllib.request import urlopen\n",
    "import json5 as json5\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from typing import Callable, Literal\n",
    "from copy import copy\n",
    "from datetime import datetime, timedelta, date\n",
    "from calendar import monthrange, month_abbr\n",
    "import plotly.express as px\n",
    "from json2txttree import json2txttree\n",
    "from python_utils.web_screenshot import web_screenshot_async\n",
    "from python_utils.get_browser import get_browser_page_async\n",
    "from typing import Any\n",
    "from toolz import groupby\n",
    "import numpy as np\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collective_scheme_type = dict[Literal['Scheme'], str] | dict[Literal['Funds'], list[str]]\n",
    "\n",
    "def strip_start_end(s1: str, last_acceptable_characters = ')'):\n",
    "    if type(s1) != str or s1 is None:\n",
    "        return ''\n",
    "    # Define a regex pattern to match 'and' followed by any non-alphabet characters at the end of the string\n",
    "    and_pattern = r'\\band[^a-zA-Z]*$'\n",
    "    # Define a regex pattern to match any non-alphabet characters at the start of the string\n",
    "    non_alphabet_start = r'^[^a-zA-Z]+'\n",
    "    # Define a regex pattern to match any non-alphabet characters at the end of the string\n",
    "    non_alphabet_end = f'[^a-zA-Z{last_acceptable_characters}]+$'\n",
    "    # Define a regex pattern to match the phrase \"comprising of|which comprises of\"\n",
    "    comprising_of_pattern = r'comprising of|which comprises of'\n",
    "    # Replace multiple spaces with a single space\n",
    "    multiple_white_space = r'\\s+'\n",
    "    s2 = re.sub(comprising_of_pattern, '', s1)\n",
    "    s3 = re.sub(and_pattern, '', s2)\n",
    "    s4 = re.sub(non_alphabet_start, '', s3)\n",
    "    s5 = re.sub(non_alphabet_end, '', s4)\n",
    "    s6 = re.sub(multiple_white_space, ' ', s5)\n",
    "    s7 = s6.strip()\n",
    "    # Recursively apply the function if any of the patterns still match the string\n",
    "    while any(re.match(p, s7) for p in [and_pattern, non_alphabet_start, non_alphabet_end, comprising_of_pattern]):\n",
    "        return strip_start_end(s5)\n",
    "    # remove non ASCII characters\n",
    "    s8 = s7.encode('ascii', errors='ignore').decode()\n",
    "    # Return the cleaned string\n",
    "    return s8\n",
    "\n",
    "def hacky_normalizer(val: str):\n",
    "    val = val.strip().upper()\n",
    "    # Replace special characters with underscore\n",
    "    modified_string = re.sub(r'[^a-zA-Z0-9\\%()_]', '_', val)\n",
    "    # Replace multiple consecutive underscores with a single underscore\n",
    "    modified_string = re.sub(r'_+', '_', modified_string)\n",
    "    return modified_string\n",
    "\n",
    "def dynamic_callback(callback, *args):\n",
    "    sig = inspect.signature(callback)\n",
    "    param_count = len(sig.parameters)\n",
    "    \n",
    "    if param_count == 0:\n",
    "        return callback()\n",
    "    return callback(*args[:param_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sourcing and Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approved Collective Schemes\n",
    "\n",
    "To get a comprehensive and up to date list of approved collective managers, we crawled Capital Markets Authrity (CMA). They have  published a list of approved schemes <https://www.cma.or.ke/licensees-market-players/> and <https://licensees.cma.or.ke/licenses/15/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshots of the pages\n",
    "\n",
    "Lets start with some screenshots of the pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### www.cma.or.ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collective_investment_schemes_click_fn(page: Page):\n",
    "    await page.waitForSelector('ul.module-accordion')\n",
    "    elements = await page.querySelectorAll('li .accordion-title')\n",
    "    # Iterate through the elements to find the one containing 'APPROVED COLLECTIVE INVESTMENT SCHEMES'\n",
    "    for element in elements:\n",
    "        text_content = await page.evaluate('(element) => element.textContent', element)\n",
    "        if 'APPROVED COLLECTIVE INVESTMENT SCHEMES' in text_content:\n",
    "            # Click on the target element\n",
    "            await element.click()\n",
    "            accordion_element = await page.waitForSelector('li.current.builder-accordion-active')\n",
    "            await page.evaluate(\"\"\"() => {\n",
    "                document.querySelector('#headerwrap').style.display = 'none';\n",
    "                document.querySelector('.pojo-a11y-toolbar-toggle').style.display = 'none';\n",
    "            }\"\"\")\n",
    "            await asyncio.sleep(1)\n",
    "            return accordion_element\n",
    "    print('Element not found')\n",
    "\n",
    "# Take a screenshot\n",
    "await web_screenshot_async(\n",
    "    # Fund manager URL\n",
    "    \"https://www.cma.or.ke/licensees-market-players/\", \n",
    "    action = collective_investment_schemes_click_fn,\n",
    "    width = 1000, \n",
    "    screenshot_options = None,\n",
    "    crop_options = { 'bottom': 500 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### licensees.cma.or.ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collective_investment_schemes_2(page: Page):\n",
    "    return await page.querySelector('table')\n",
    "\n",
    "# Take a screenshot\n",
    "await web_screenshot_async(\n",
    "    # Fund manager URL\n",
    "    \"https://licensees.cma.or.ke/licenses/15/\", \n",
    "    action = collective_investment_schemes_2,\n",
    "    width = 1500, \n",
    "    screenshot_options = None,\n",
    "    crop_options = { 'bottom': 500 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crawling\n",
    "\n",
    "Next, let's try grab the fund managers table into a dataframe that we can work with.\n",
    "Below is the list of all the certified fund mangers in Kenya by CMA.^[Approved Fund Managers by CMA. <https://www.cma.or.ke/licensees-market-players/>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_collective_scheme_name(para: Tag):\n",
    "    full_name = ' '.join([i.get_text(strip=True) for i in para.find_all('strong')])\n",
    "    return strip_start_end(full_name)\n",
    "\n",
    "def make_collective_unit_obj(tbody_tr_td: Tag) -> collective_scheme_type:\n",
    "    return {\n",
    "        'Scheme': extract_collective_scheme_name(tbody_tr_td.find('p') or tbody_tr_td),\n",
    "        'Funds': [\n",
    "            strip_start_end(i.get_text(separator=' ', strip=True)) \n",
    "            for i \n",
    "            in tbody_tr_td.select('ul li')\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def fetch_collective_schemes_1():\n",
    "    CMA_market_players_html: str = urlopen(\"https://www.cma.or.ke/licensees-market-players/\").read()\n",
    "    investment_schemes_table_html = BeautifulSoup(CMA_market_players_html, \"html.parser\")\\\n",
    "        .find('span', string=\"APPROVED COLLECTIVE INVESTMENT SCHEMES\")\\\n",
    "        .find_parent('li')\\\n",
    "        .find('table')\n",
    "    return [\n",
    "        make_collective_unit_obj(tbody_tr_td)\n",
    "        for tbody_tr_td \n",
    "        in investment_schemes_table_html.select('tbody tr td')\n",
    "    ]\n",
    "\n",
    "def fetch_collective_schemes_2():\n",
    "    CMA_market_players_html: str = urlopen(\"https://licensees.cma.or.ke/licenses/15/\").read()\n",
    "    investment_schemes_table_html = BeautifulSoup(CMA_market_players_html, \"html.parser\")\\\n",
    "        .find('table')\n",
    "    return [\n",
    "        make_collective_unit_obj(tbody_tr_td)\n",
    "        for tbody_tr_td \n",
    "        in investment_schemes_table_html.select('tbody tr > :first-child')\n",
    "    ]\n",
    "\n",
    "# For example: \n",
    "#       Orient Umbrella Collective Investment Scheme (formerly Alphafrica Umbrella Fund) => \n",
    "#       Orient Umbrella Collective Investment Scheme\n",
    "def remove_quoted_str(str1: str): return re.sub(r'\\(.*?(?!\\)).*?$', '', str1 or '').strip()\n",
    "def remove_rendadant_words(str1: str):\n",
    "    return re.sub(\n",
    "        r'\\b(scheme|schemes|trust|trusts|specialized|special|funds|fund|unit|units|collective|investment)\\b\\s*', \n",
    "        '', \n",
    "        str1 or '',\n",
    "        flags=re.IGNORECASE).strip()\n",
    "def remove_special_words(str1: str):\n",
    "    return re.sub(\n",
    "        r'\\b(specialized|special)\\b\\s*', \n",
    "        '', \n",
    "        str1 or '',\n",
    "        flags=re.IGNORECASE).strip()\n",
    "\n",
    "def make_merge_key(str1: str): return hacky_normalizer(remove_rendadant_words(remove_quoted_str(str1)))\n",
    "\n",
    "def merge_collective_schemes(schemes_list: list[collective_scheme_type]) -> collective_scheme_type:\n",
    "    all_names: dict[str, list[str]] = groupby(\n",
    "        make_merge_key, [unit_obj['Scheme'] for unit_obj in schemes_list])\n",
    "    all_schemes: dict[str, list[str]] = groupby(\n",
    "        make_merge_key, [scheme for unit_obj in schemes_list for scheme in unit_obj['Funds']])\n",
    "    return {\n",
    "        'Scheme': sorted(\n",
    "            [name for values in all_names.values() for name in values], \n",
    "            key = lambda x: len(remove_special_words(remove_quoted_str(x))), \n",
    "            reverse=True\n",
    "        )[0],\n",
    "        'Funds': [\n",
    "            sorted(schemes, key = lambda x: len(x), reverse=True)[0]\n",
    "            for schemes \n",
    "            in all_schemes.values()\n",
    "        ]\n",
    "    }\n",
    "\n",
    "collective_schemes_1 = fetch_collective_schemes_1()\n",
    "collective_schemes_2 = fetch_collective_schemes_2()\n",
    "collective_schemes_1_2 = collective_schemes_1 + collective_schemes_2\n",
    "collective_schemes_grouped_by_name = groupby(\n",
    "    lambda x: make_merge_key(x['Scheme']), collective_schemes_1_2)\n",
    "collective_schemes = [\n",
    "    merge_collective_schemes(collective_schemes) \n",
    "    for collective_schemes \n",
    "    in collective_schemes_grouped_by_name.values()]\n",
    "collective_schemes_df = pd.DataFrame(collective_schemes)\n",
    "collective_schemes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `49` **unique** and approved unit trust schemes as at {{< meta date-modified >}}. Schemes are normally managed by approved investment bank managers or approved fund managers. By investment bank, its not the traditional bank, but rather a CMA approved investment bank, such as \"BLA BLA BLA\". Traditional banks can also have fund managers. for example KCB has KCB Asset managers which is approved by CMA to manage \"BLA BLA BLA\". If an investment vehicle dont have an approved fund mannger ot investment bank, but they would like to have an approved scheme, they can norminate existing fund managers to manage the scheme for them. For example, *Mali Money Market Fund* ^[[Frequently Asked Questions / Mali](https://www.safaricom.co.ke/media-center-landing/frequently-asked-questions/mali)] ^[[Safaricom to launch unit trust, new savings service](https://www.businessdailyafrica.com/bd/markets/capital-markets/safaricom-to-launch-unit-trust-new-savings-service-2288556)] which is wholly or partly owned by the Kenyan Telecommunications company, Safaricom PLC ^[[M-PESA / M-PESA Services / Wealth / Mali](https://www.safaricom.co.ke/main-mpesa/m-pesa-services/wealth/mali)], is not listed among licenced fund managers. According to Business Daily ^[[Safaricom's Mali unit trust asset base hits Sh1.4bn](https://www.businessdailyafrica.com/bd/markets/capital-markets/safaricom-s-mali-unit-trust-asset-base-hits-sh1-4bn--4582142)], Mali MMF is administered by Genghis Capital Limited, which is listed by CMA as an Investment Bank. Genghis Capital Limited also has its own unit trust fund called Gencap Hela Imara Money Market Fund ^[[Genghis Capital Unit Trust Fund](https://genghis-capital.com/asset-management/money-market-fund/)]. This may or may not raise a potential conflict of interest. \n",
    "Similaraly, there are fund managers that no longer offer Unit Turst investments under Money Makrket Funds, such as Zimele ^[[Zimele Savings Plan Transition: From Money Market to Fixed Income Fund](https://www.zimele.co.ke/zimele-savings-plan-transition-from-money-market-to-fixed-income-fund/)]. Before you choose a fund manager, make sure you do your due diligence, and understand the risks you are willing to take.\n",
    "\n",
    ":::{.callout-note}\n",
    "Always invest with caution! When important information is missing, unclear or overly complicated.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Data\n",
    "\n",
    "Despite the requirements to have the daily yield published in two national newspapers, it is fairly tasking to find a good data source. Also, since there dont have to publish the newspapers that have digital precenese, it also becomes difficult to capture all yileds without visiting the library and grabbing the actual physical copies, which makes this task very expesnsive. Again, getting historical data is also not free, most old newspaper records are sold, adding up the cost. Fortunately, since 2014, Cytonn Fund Managers has been doing free market research, and publishing them at <https://cytonnreport.com/>. A few fund managers publish their daily yields at their websites, but without historical data; just the current day's yield, which effectively makes this data unuseful for analysis.\n",
    "\n",
    "We settled on crawling and analysing the massive cytton research data that is publicly available since 2014. With over 600 reports with, we crawl each of the reports in a way that doesnt break their systems, or deny others the service, extract the table, aggregate the table results and analyze the tables. We checked with Cytonn's terms of service. users are allowed to use their copyright data in accordance with fair use/dealing, ^[Reproduction is prohibited other than in accordance with the copyright notice, which forms part of these terms and conditions. <https://cytonn.com/terms-of-use> ]. To allow others to reproduce this analysys, we will save a copy of the crawled raw data for future researchers and data enthusisists.\n",
    "\n",
    "Cytonn has reports in two websites, <https://cytonn.com/researches> and <https://cytonnreport.com/research>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshots of Cytonn Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cytonn.com page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a screenshot\n",
    "await web_screenshot_async(\n",
    "    \"https://cytonn.com/researches\",\n",
    "    width = 1500,\n",
    "    height = 1200,\n",
    "    screenshot_options = {'fullPage': False })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cytonnreport.com page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def cytonnreport_fn(page: Page):\n",
    "    await page.waitForSelector('.grid-x > .pagination')\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "# Take a screenshot\n",
    "await web_screenshot_async(\n",
    "    \"https://cytonnreport.com/research\",\n",
    "    action = cytonnreport_fn,\n",
    "    width = 1500,\n",
    "    height = 1200,\n",
    "    screenshot_options = {'fullPage': False })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Money Market Fund Yield Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: preview-image\n",
    "\n",
    "# Define a function that selects a table by its header text\n",
    "def select_table_by_title(target_header_text: str):\n",
    "    # Define a nested asynchronous function that takes a Page object as an argument\n",
    "    async def fn(page: Page):\n",
    "        # Wait for any table element to be present on the page\n",
    "        await page.waitForSelector('table')\n",
    "        # Query and collect all table elements on the page\n",
    "        table_elements = await page.querySelectorAll('table')\n",
    "        # Iterate through each table element\n",
    "        for table_element in table_elements:\n",
    "            # Query and collect all header cells in the current table\n",
    "            table_headers = await table_element.querySelectorAll('thead tr td')\n",
    "            # Iterate through each header cell\n",
    "            for table_header in table_headers:\n",
    "                # Extract the text content of the current header cell\n",
    "                header_text:str = await page.evaluate('(element) => element.textContent', table_header)\n",
    "                # Check if the header text starts with the target text\n",
    "                if header_text.startswith(target_header_text):\n",
    "                    # If a match is found, return the current table element\n",
    "                    return table_element\n",
    "    return fn\n",
    "\n",
    "await web_screenshot_async(\n",
    "    # URL to take a screenshot of\n",
    "    \"https://cytonnreport.com/research/cytonn-monthly-\",\n",
    "    # Action deciding WHAT (element) or WHEN (eg: click) to take the screenshot\n",
    "    action = select_table_by_title('Cytonn Report: Money Market Fund Yield'),\n",
    "    width = 1000, \n",
    "    screenshot_options = None,\n",
    "    crop_options = { 'bottom': 500 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At <https://cytonn.com/researches>, we can crawl and parse HTML, but it could be very slow. We notice that <https://cytonnreport.com/research>, the exact same data is displayed, but using a background request, <https://cytonnreport.com/get/allreports>. We can use this to crawl multiple reports faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_all_cytonn_reports(per_page_count: int = 10):\n",
    "    \"\"\"\n",
    "    Retrieves all Cytonn reports from the Cytonn Report website.\n",
    "\n",
    "    Args:\n",
    "        per_page_count (int, optional): The number of reports to retrieve per page. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of all the retrieved reports.\n",
    "    \"\"\"\n",
    "    ...\n",
    "    page, browser = await get_browser_page_async()\n",
    "    reports_url = \"https://cytonnreport.com/get/allreports\"\n",
    "    reports_headers: dict = None\n",
    "    reports_method: str = None\n",
    "    async def catch_request(request: Request):\n",
    "        nonlocal reports_headers\n",
    "        nonlocal reports_method\n",
    "        if request.url == reports_url:\n",
    "            reports_headers = request.headers.copy()\n",
    "            reports_method = request.method\n",
    "            await request.continue_()\n",
    "        else:\n",
    "            await request.continue_()\n",
    "    async def get_cytonn_reports(current_page: int):\n",
    "        javascript_fetch_fn = f'''\n",
    "            async () => {{\n",
    "                try {{\n",
    "                    const response = await fetch(\n",
    "                        \"{reports_url}\", \n",
    "                        {{\n",
    "                            \"headers\": {json.dumps(reports_headers)},\n",
    "                            \"method\": \"{reports_method}\",\n",
    "                            \"body\": {json.dumps(json.dumps(\n",
    "                                {\n",
    "                                    \"pagination\": {\n",
    "                                        \"per_page\": per_page_count, \n",
    "                                        \"current_page\": current_page\n",
    "                                    }\n",
    "                                }))},\n",
    "                            \"referrer\": \"https://cytonnreport.com/research\",\n",
    "                            \"referrerPolicy\": \"no-referrer-when-downgrade\",\n",
    "                            \"mode\": \"cors\",\n",
    "                            \"credentials\": \"include\"\n",
    "                        }});\n",
    "                    if (!response.ok) {{\n",
    "                        throw new Error(`HTTP error! status: ${{response.status}}`);\n",
    "                    }}\n",
    "                    const json = await response.json();\n",
    "                    return json;\n",
    "                }} catch (error) {{\n",
    "                    console.error('Fetch error:', error);\n",
    "                    throw error; // Re-throw to allow calling code to handle it\n",
    "                }}\n",
    "            }}\n",
    "        '''\n",
    "        response_json = await page.evaluate(javascript_fetch_fn)\n",
    "        return response_json\n",
    "    # Enable request interception\n",
    "    await page.setRequestInterception(True)\n",
    "    # Attach the request handler\n",
    "    page.on('request', lambda request: asyncio.ensure_future(catch_request(request)))\n",
    "    # Navigate to the desired URL\n",
    "    await page.goto(\"https://cytonnreport.com/research\")\n",
    "    while not reports_headers:\n",
    "        await asyncio.sleep(1)\n",
    "    current_page = 1\n",
    "    all_reports = []\n",
    "    pbar: tqdm = None\n",
    "    while True:\n",
    "        reports_response = await get_cytonn_reports(current_page)\n",
    "        reports = reports_response['data'] if reports_response else []\n",
    "        if len(reports) > 0:\n",
    "            total = reports_response['total']\n",
    "            pbar = pbar or tqdm(total=total)\n",
    "            pbar.update(len(reports))\n",
    "            all_reports.extend(reports)\n",
    "            last_page = reports_response['last_page']\n",
    "            if last_page == current_page:\n",
    "                break\n",
    "            current_page += 1\n",
    "        else:\n",
    "            break\n",
    "        await asyncio.sleep(0.4)\n",
    "    await browser.close()\n",
    "    if pbar:\n",
    "        pbar.close()\n",
    "    return all_reports\n",
    "\n",
    "all_cytonn_reports = await get_all_cytonn_reports()\n",
    "print(f'There are {len(all_cytonn_reports)} reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the JSON into dataframe\n",
    "all_cytonn_reports_df = pd.DataFrame(all_cytonn_reports)\n",
    "with pd.option_context(\n",
    "  'display.max_columns', None, \n",
    "  'display.max_colwidth', 100):\n",
    "  display(all_cytonn_reports_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed, the dataset above is a bit complex and diffucult to uderstand or analyze. This is because alot of information is contained in the reports. There is real estate data, money market funds dataset, fund managers over the years,  As such, we will try to extract money market funds (KES) from the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cofirms all the records have are unique\n",
    "len(all_cytonn_reports_df), len(all_cytonn_reports), len(all_cytonn_reports_df['id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratore and Clean the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to extract the details of money market funds (KES)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cytonn_reports_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cytonn_reports_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cytonn_reports_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cytonn_reports_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a tree structure of one record, to visualize the objects and their inner properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_structure = json2txttree(all_cytonn_reports[:1])\n",
    "min_topics = min(len(i.get('topics', [])) for i in all_cytonn_reports)\n",
    "max_topics = max(len(i.get('topics', [])) for i in all_cytonn_reports)\n",
    "json_structure = json_structure.replace('└─  (array)', f'└─  (array) [{len(all_cytonn_reports)}]')\n",
    "json_structure = json_structure.replace('\"topics\" (array)', f'\"topics\" (array) [{min_topics} - {max_topics}]')\n",
    "\n",
    "print(json_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full article is formed by articles. Each `topics` is a subsection, with `title` being the header and `body` being the content. We will merge all bodies from the articles to form the entire report HTML, which we will parse to extract the Money Market Funds yields tables. In addition, we are also going to add the main `body` and main `summary` and topics `summary` to encure we capture any table we might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYTONN_RECORD_LITERALS = Literal['summary', 'body', 'topics', 'researchdate']\n",
    "def get_report_HTML(report: dict[CYTONN_RECORD_LITERALS, Any]) -> str:\n",
    "    summary_html = report['summary']\n",
    "    body_html = report['body']\n",
    "    topics_html = ''.join([f\"{i['summary']} \\n\\n {i['body']}\" for i in report['topics']])\n",
    "    return f\"{summary_html} \\n {body_html} \\n {topics_html}\"\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# HTML(get_report_HTML(all_cytonn_reports[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Dates\n",
    "\n",
    "There are some summary tables that have dates such as `Q1'2023`, `Q1'2023 (%)`, `FY'2023`, `FY'2023 (%)`, `Q1'2024`, `Q1'2024 (%)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await web_screenshot_async(\n",
    "    # URL to take a screenshot of\n",
    "    \"https://cytonnreport.com/research/q1-2024-unit-trust-funds-performance-note\",\n",
    "    # Action deciding WHAT (element) or WHEN (eg: click) to take the screenshot\n",
    "    action = select_table_by_title('Cytonn Report: Assets Under Management (AUM) for the Approved Collective Investment Schemes'),\n",
    "    width = 1000, \n",
    "    screenshot_options = None,\n",
    "    crop_options = { 'bottom': 500 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function will help parse such time ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_range(month, year):\n",
    "    # Convert month name to number\n",
    "    month_num = [i.lower() for i in month_abbr].index(month.lower())\\\n",
    "        if len(month) > 0 and any([i.lower() == month.lower() for i in month_abbr])\\\n",
    "        else datetime.strptime(month, '%B').month\n",
    "    # Get the last day of the month\n",
    "    _, last_day = monthrange(int(year), month_num)\n",
    "    # Create date objects for the first and last day of the month\n",
    "    start_date = date(int(year), month_num, 1)\n",
    "    end_date = date(int(year), month_num, last_day)\n",
    "    return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')\n",
    "parse_date_pattern_months = (\n",
    "    \"JAN|JANUARY|FEB|FEBRUARY|MAR|MARCH|APR|APRIL|MAY|\"\n",
    "    \"JUN|JUNE|JUL|JULY|AUG|AUGUST|SEP|SEPTEMBER|\"\n",
    "    \"OCT|OCTOBER|NOV|NOVEMBER|DEC|DECEMBER\"\n",
    ")\n",
    "parse_date_pattern = rf'(?:(\\d{{2}})[_|\\s|-]*)?({parse_date_pattern_months})[_|\\s|-]*(\\d{{4}})'\n",
    "\n",
    "def parse_fiscal_period_dates(date_string: str) -> (tuple[str, str] | None):\n",
    "    \"\"\"\n",
    "    This function parses a date string representing a fiscal period \n",
    "    (Fiscal/Financial Year, Quarter, or Half-year), year, or date and returns the corresponding \n",
    "    start and end dates.\n",
    "    \"\"\"\n",
    "    extracted_date = re.search('^' + parse_date_pattern + '$', date_string, re.IGNORECASE)\n",
    "    if extracted_date:\n",
    "        search_date, search_month, search_year = extracted_date.groups()\n",
    "        if search_date:\n",
    "            month_num = datetime.strptime(search_month, '%B').month\n",
    "            return datetime(int(search_year), month_num, int(search_date)).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            return get_date_range(search_month, search_year)\n",
    "    if re.match(r\"^\\d{4}$\", date_string, re.IGNORECASE):\n",
    "        date_string = f\"FY'{date_string}\"\n",
    "    # Define a regex pattern to match fiscal periods (FY, Q1-Q4, H1-H2) followed by a year, or just an year\n",
    "    pattern = r\"^(FY|Q[1-4]|H[1-2])['|_|\\s]*(\\d{4})$\"\n",
    "    # Try to match the input string against the pattern\n",
    "    match = re.match(pattern, date_string, re.IGNORECASE)\n",
    "    # If no match is found, return None\n",
    "    if not match:\n",
    "        return None\n",
    "    # Extract the period type and year from the match\n",
    "    period, year = match.groups()\n",
    "    year = int(year)\n",
    "    # Handle Fiscal Year (FY) case\n",
    "    if period.upper() == 'FY':\n",
    "        start_date = datetime(year, 1, 1)\n",
    "        end_date = datetime(year, 12, 31)\n",
    "    # Handle Quarter (Q1-Q4) cases\n",
    "    elif period.upper().startswith('Q'):\n",
    "        quarter = int(period[1])\n",
    "        start_month = (quarter - 1) * 3 + 1\n",
    "        start_date = datetime(year, start_month, 1)\n",
    "        # Calculate end date of the quarter\n",
    "        end_date = start_date.replace(month=start_month + 2) + timedelta(days=32)\n",
    "        end_date = end_date.replace(day=1) - timedelta(days=1)\n",
    "    # Handle Half-year (H1-H2) cases\n",
    "    elif period.upper().startswith('H'):\n",
    "        half = int(period[1])\n",
    "        start_month = (half - 1) * 6 + 1\n",
    "        start_date = datetime(year, start_month, 1)\n",
    "        # Calculate end date of the half-year\n",
    "        end_date = start_date.replace(month=start_month + 5) + timedelta(days=32)\n",
    "        end_date = end_date.replace(day=1) - timedelta(days=1)\n",
    "    # Return start and end dates formatted as strings\n",
    "    return (start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "def TEST_get_fiscal_period_dates():\n",
    "    # Test the function\n",
    "    test_dates = [\n",
    "        \"FY'2019\", \"Q1'2020\", \"H1'2019\", \"fy 2018\", \"q32021\", \"h2_2022\", \"2020\", '2019',\n",
    "        'JUNE_2020', '01_NOVEMBER_2017', \"H3'2020\"\n",
    "    ]\n",
    "    for expanding_value in test_dates:\n",
    "        result = parse_fiscal_period_dates(expanding_value)\n",
    "        if result:\n",
    "            print(f\"{expanding_value}: {result}\")\n",
    "        else:\n",
    "            print(f\"{expanding_value}: Invalid format\")\n",
    "TEST_get_fiscal_period_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a Effective Annual Rate(KES Money Market Fund) and Total Assets Under Management (Collective Investment Schemes)\n",
    "\n",
    "The `Extracted_Scheme_Entry` class below represents and validates a financial record entry. It validates `record type` (_Assets Under Management_ or _Effective Annual Rate_), `date`, `value`, and `fund manager`. The class also maintains lists of non-existent fund managers and invalid records. Assets under management (AUM) is the market value of the investments managed by the fund manager on behalf of clients, inluding MMF, FIXED, balanced, equity, etc. The effective annual interest rate is the actual return of the Money Market Fund accounts **ONLY**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: True, ['2024-03-01', 1000000.0, 'Britam MMF(KES)']\n",
      "Valid: True, [['2024-01-01', '2024-06-30'], 5.5, 'UAP Old Mutual MMF(KES)']\n",
      "Valid: False (invalid date), [None, 1000000.0, 'Sanlam MMF(KES)']\n",
      "Valid: False (invalid value), ['2024-03-01', None, 'Britam MMF(KES)']\n",
      "Valid: False (unmapped scheme), ['2024-03-01', 1000000.0, None]\n",
      "\"britam sanlam\" has more that two matches! ['Britam MMF(KES)', 'Sanlam MMF(KES)']\n",
      "Valid: False (2 funds matched), ['2024-03-01', 1000000.0, None]\n",
      "Valid: False (USD MMF), ['2024-03-01', 1000000.0, None]\n",
      "\n",
      "Invalid Funds: ['unknown scheme', 'britam sanlam', 'Britam USD Dollar Fund']\n",
      "\n",
      "Invalid Dates: ['invalid-date']\n",
      "\n",
      "Invalid Values: ['invalid-value']\n"
     ]
    }
   ],
   "source": [
    "class Extracted_Scheme_Entry:\n",
    "    \"\"\"\n",
    "    A class to represent and validate financial entry information.\n",
    "    \n",
    "    Class Attributes:\n",
    "    INVALID_FUNDS (list[str]): Stores funds not found in the mapping.\n",
    "    INVALID_DATES (list[str]): Stores entry dates not valid.\n",
    "    INVALID_VALUES (list[str]): Stores entry values not valid.\n",
    "    TYPE_ASSETS_UNDER_MANAGEMENT (str): Constant for Assets Under Management type.\n",
    "    TYPE_EFFECTIVE_ANNUAL_RATE (str): Constant for Effective Annual Rate type.\n",
    "    \"\"\"\n",
    "    INVALID_SCHEMES: list[str] = []\n",
    "    INVALID_DATES: list[str] = []\n",
    "    INVALID_VALUES: list[str] = []\n",
    "    TYPE_ASSETS_UNDER_MANAGEMENT: str = 'ASSETS_UNDER_MANAGEMENT' # Assets Under Management\n",
    "    TYPE_EFFECTIVE_ANNUAL_RATE: str = 'EFFECTIVE_ANNUAL_RATE' # Effective Annual Rate\n",
    "\n",
    "    def __init__(self, \n",
    "                 entry_type: Literal['ASSETS_UNDER_MANAGEMENT', 'EFFECTIVE_ANNUAL_RATE'], \n",
    "                 entry_date: str, \n",
    "                 entry_value: str, \n",
    "                 entry_scheme: str,\n",
    "                 scheme_filter_function: Callable[[str], list[str]]):\n",
    "        \"\"\"\n",
    "        Initialize a RecordEntry instance with validated attributes.\n",
    "        \n",
    "        Args:\n",
    "        entry_type (str): Type of the record (TYPE_ASSETS_UNDER_MANAGEMENT or TYPE_EFFECTIVE_ANNUAL_RATE).\n",
    "        entry_date (str): Date of the record (2024-03-01) or Financial period (H1'2024).\n",
    "        entry_value (str): Value of the record.\n",
    "        entry_scheme (str): Name of the MMF(KES) fund\n",
    "        fund_manager_filter_predicate (Callable): A predicate to filter and return matched MMF(KES) fund for validation.\n",
    "        \"\"\"\n",
    "        self.entry_type = Extracted_Scheme_Entry.validate_type(entry_type)\n",
    "        self.entry_date = Extracted_Scheme_Entry.validate_date(entry_date)\n",
    "        self.entry_value = Extracted_Scheme_Entry.validate_value(entry_value)\n",
    "        self.entry_scheme = Extracted_Scheme_Entry.validate_scheme(entry_scheme, scheme_filter_function)\n",
    "        if self.entry_date is None:\n",
    "            Extracted_Scheme_Entry.INVALID_DATES.append(entry_date)\n",
    "        if self.entry_value is None:\n",
    "            Extracted_Scheme_Entry.INVALID_VALUES.append(entry_value)\n",
    "        if self.entry_scheme is None:\n",
    "            Extracted_Scheme_Entry.INVALID_SCHEMES.append(entry_scheme)\n",
    "\n",
    "    def is_valid(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the record is valid (all attributes are non-empty).\n",
    "        \"\"\"\n",
    "        is_valid = \\\n",
    "            bool(self.entry_type) \\\n",
    "            and bool(self.entry_date) \\\n",
    "            and bool(self.entry_value) \\\n",
    "            and bool(self.entry_scheme)\n",
    "        return is_valid\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_scheme(value: str, filter_predicate: Callable[[str], list[str]]) -> str|None:\n",
    "        \"\"\"\n",
    "        Validate and standardize the date or financial period.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            value = str(value or '').lower()\n",
    "            # These represent USD MMF's\n",
    "            EXCLUDES = ['Dollar', 'USD']\n",
    "            is_USD_MMF = any((exclude.lower() in value) for exclude in EXCLUDES)\n",
    "            if not is_USD_MMF:\n",
    "                names = filter_predicate(value)\n",
    "                if len(names) == 1:\n",
    "                    return names[0]\n",
    "                if len(names) > 1:\n",
    "                    print(f'\"{value}\" has more that two matches! {names}')\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_date(value: str) -> str|tuple[str, str]|None:\n",
    "        \"\"\"\n",
    "        Validate and standardize the date\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _date_range = parse_fiscal_period_dates(value)\n",
    "            if type(_date_range) == tuple:\n",
    "                _date_range = list(_date_range)\n",
    "            return _date_range\\\n",
    "                    or datetime.strptime(value, \"%Y-%m-%d\").strftime('%Y-%m-%d')\\\n",
    "                    or None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_value(value: str|float) -> str|None:\n",
    "        \"\"\"\n",
    "        Validate and clean the entry value.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if type(value) == float:\n",
    "                    return value\n",
    "            # remove percentage sign\n",
    "            value = value.rstrip('%')\n",
    "            # remove comma and white space\n",
    "            value = ''.join([i for i in value if i not in [' ', ',', '-']])\n",
    "            return float(value) if len(value) > 0 else None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_type(value: str) -> Literal['ASSETS_UNDER_MANAGEMENT', 'EFFECTIVE_ANNUAL_RATE']:\n",
    "        \"\"\"\n",
    "        Validate the record type.\n",
    "        \n",
    "        Args:\n",
    "        value (str): The record type to validate.\n",
    "        \n",
    "        Raises:\n",
    "        TypeError exception.\n",
    "        \"\"\"\n",
    "        value = (value or '').upper()\n",
    "        if value in [Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE]:\n",
    "            return value\n",
    "        raise TypeError(f\"{value} is not proper entry Type!\")\n",
    "    \n",
    "def TEST_MoneyMarketFund_KES_RecordEntry():\n",
    "    # Test the class\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"2024-03-01\",\n",
    "            \"entry_value\": \"1,000,000\",\n",
    "            \"entry_scheme\": \"britam\",\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE,\n",
    "            \"entry_date\": \"H1'2024\",\n",
    "            \"entry_value\": \"5.5%\",\n",
    "            \"entry_scheme\": \"old mutual\",\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"invalid-date\",\n",
    "            \"entry_value\": \"1,000,000\",\n",
    "            \"entry_scheme\": \"sanlam\",\n",
    "            \"invalid\": \"invalid date\"\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"2024-03-01\",\n",
    "            \"entry_value\": \"invalid-value\",\n",
    "            \"entry_scheme\": \"britam\",\n",
    "            \"invalid\": \"invalid value\"\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"2024-03-01\",\n",
    "            \"entry_value\": \"1,000,000\",\n",
    "            \"entry_scheme\": \"unknown scheme\",\n",
    "            \"invalid\": \"unmapped scheme\"\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"2024-03-01\",\n",
    "            \"entry_value\": \"1,000,000\",\n",
    "            \"entry_scheme\": \"britam sanlam\",\n",
    "            \"invalid\": \"2 funds matched\"\n",
    "        },\n",
    "        {\n",
    "            \"entry_type\": Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT,\n",
    "            \"entry_date\": \"2024-03-01\",\n",
    "            \"entry_value\": \"1,000,000\",\n",
    "            \"entry_scheme\": \"Britam USD Dollar Fund\",\n",
    "            \"invalid\": \"USD MMF\"\n",
    "        },\n",
    "    ]\n",
    "    # Define the fund filter function\n",
    "    test_fund_map = [\n",
    "        (\n",
    "            'Britam MMF(KES)',\n",
    "            ['britam', 'british-american', 'british', 'american']\n",
    "        ),\n",
    "        (\n",
    "            'UAP Old Mutual MMF(KES)',\n",
    "            ['old mutual', 'uap old mutual', 'uap']\n",
    "        ),\n",
    "        (\n",
    "            'Sanlam MMF(KES)',\n",
    "            ['sanlam', 'sanlam investments']\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    def test_fund_filter(value: str):\n",
    "        value = value.lower()\n",
    "        names = [name for name, aliases in test_fund_map if any(alias in value for alias in aliases)]\n",
    "        return names\n",
    "\n",
    "    # Run tests\n",
    "    for test_case in test_cases:\n",
    "        entry = Extracted_Scheme_Entry(\n",
    "            test_case[\"entry_type\"],\n",
    "            test_case[\"entry_date\"],\n",
    "            test_case[\"entry_value\"],\n",
    "            test_case[\"entry_scheme\"],\n",
    "            test_fund_filter\n",
    "        )\n",
    "        cases = [entry.entry_date, entry.entry_value, entry.entry_scheme]\n",
    "        invalid = f\" ({test_case.get('invalid')})\" if test_case.get('invalid') else ''\n",
    "        print(f\"Valid: {entry.is_valid()}{invalid}, {cases}\")\n",
    "\n",
    "    # Print invalid entries\n",
    "    print(\"\\nInvalid Funds:\", Extracted_Scheme_Entry.INVALID_SCHEMES)\n",
    "    print(\"\\nInvalid Dates:\", Extracted_Scheme_Entry.INVALID_DATES)\n",
    "    print(\"\\nInvalid Values:\", Extracted_Scheme_Entry.INVALID_VALUES)\n",
    "    Extracted_Scheme_Entry.INVALID_SCHEMES = []\n",
    "    Extracted_Scheme_Entry.INVALID_DATES = []\n",
    "    Extracted_Scheme_Entry.INVALID_VALUES = []\n",
    "TEST_MoneyMarketFund_KES_RecordEntry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a fund collective schemes map with a tuple of `name` and `aliases` because the records don't have a simple or stardard naming in the Cytonn reports. As such, we need to use very unique and simple names that we can use to match abitrary Money market funds names from the crawled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://licensees.cma.or.ke/\n",
    "# https://licensees.cma.or.ke/licenses/15/\n",
    "# https://licensees.cma.or.ke/licenses/8/\n",
    "# https://www.rba.go.ke/registered-fund-managers/\n",
    "\n",
    "SCHEME_NAME_ALIAS_MAP = [\n",
    "    # The African Alliance (AA) Kenya Shillings Fund is a money market fund by \n",
    "    # African Alliance Kenya Investment Bank Limited (the fund manager) \n",
    "    # launched on 27th April 2015.\n",
    "    # https://centwarrior.com/aa-kenya-shillings-fund/\n",
    "    # https://www.linkedin.com/posts/centwarrior_aa-kenya-shillings-fund-explained-in-2024-activity-7169322082814705664-8nwu?utm_source=share&utm_medium=member_desktop\n",
    "    # https://cytonn.com/topicals/investment-risk-analysis\n",
    "    (\n",
    "        'African Alliance Kenya Unit Trust Scheme', \n",
    "        ['african', 'alliance', 'aa kenya']\n",
    "    ),\n",
    "    (\n",
    "        'British-American Unit Trust Scheme', \n",
    "        ['britam', 'british-american', 'british', 'american']\n",
    "    ),\n",
    "    (\n",
    "        'NCBA Unit Trust Funds', \n",
    "        ['ncba', 'cba', 'commercial bank of africa']\n",
    "    ),\n",
    "    (\n",
    "        'Zimele Unit Trust Scheme', \n",
    "        ['zimele']\n",
    "    ),\n",
    "    (\n",
    "        'ICEA Unit Trust Scheme', \n",
    "        ['icea']\n",
    "    ),\n",
    "    (\n",
    "        'Standard Investment Trust Funds', \n",
    "        ['standard', 'mansa']\n",
    "    ),\n",
    "    (\n",
    "        'CIC Unit Trust Scheme', \n",
    "        ['cic']\n",
    "    ),\n",
    "    (\n",
    "        'Madison Unit Trust Fund', \n",
    "        ['Madison', 'madisson']\n",
    "    ),\n",
    "    (\n",
    "        'Dyer and Blair Unit Trust Scheme', \n",
    "        ['dyer', 'blair']\n",
    "    ),\n",
    "    (\n",
    "        'Amana Unit Trust Funds Scheme', \n",
    "        ['amana']\n",
    "    ),\n",
    "    (\n",
    "        'Diaspora Unit Trust Scheme', \n",
    "        ['diaspora']\n",
    "    ),\n",
    "    (\n",
    "        'First Ethical Opportunities Fund', \n",
    "        ['ethical', \n",
    "         # 'first', 'opportunities'\n",
    "        ]\n",
    "    ),\n",
    "    # https://www.cma.or.ke/licensees-market-players/\n",
    "    # https://genghis-capital.com/asset-management/money-market-fund/\n",
    "    (\n",
    "        'Genghis Unit Trust Funds', \n",
    "        ['hela','genghis', 'hazina', 'hisa', 'iman', 'gencap', 'compliant', 'eneza', 'genCap', 'imara']\n",
    "    ),\n",
    "    # https://www.businessdailyafrica.com/bd/markets/capital-markets/safaricom-s-mali-unit-trust-asset-base-hits-sh1-4bn--4582142\n",
    "    (\n",
    "        'Mali Money Market Fund', \n",
    "        ['mali']\n",
    "    ),\n",
    "    (\n",
    "        'Sanlam Unit Trust Scheme', \n",
    "        ['sanlam']\n",
    "    ),\n",
    "    (\n",
    "        'Nabo Africa Funds', \n",
    "        ['nabo']\n",
    "    ),\n",
    "    (\n",
    "        'Old Mutual Unit Trust Scheme', \n",
    "        ['mutual', 'old', 'Faulu']\n",
    "    ),\n",
    "    # https://equitygroupholdings.com/ke/investor-relations/eib\n",
    "    # https://www.cma.or.ke/licensees-market-players/\n",
    "    (\n",
    "        'Equity Investment Bank Collective Investment Scheme', \n",
    "        ['equity']\n",
    "    ),\n",
    "    # https://www.cma.or.ke/licensees-market-players/\n",
    "    (\n",
    "        'Dry Associates Unit Trust Scheme', \n",
    "        ['dry associates', 'dry', 'associates']\n",
    "    ),\n",
    "    (\n",
    "        'Co-op Trust Fund', \n",
    "        ['co-op', 'gratuity', 'Coop']\n",
    "    ),\n",
    "    (\n",
    "        'Apollo Unit Trust Scheme', \n",
    "        ['aggressive', 'apollo']\n",
    "    ),\n",
    "    (\n",
    "        'Cytonn Unit Trust Scheme', \n",
    "        ['cytonn']\n",
    "    ),\n",
    "    (\n",
    "        'Orient Umbrella Collective Investment Scheme (formerly Alphafrica Umbrella Fund)', \n",
    "        ['orient', 'kasha', 'alpha', 'alphafrica']\n",
    "    ),\n",
    "    (\n",
    "        'Wanafunzi Investment Unit Trust Fund', \n",
    "        ['wanafunzi']\n",
    "    ),\n",
    "    (\n",
    "        'Absa Unit Trust Funds', \n",
    "        ['absa']\n",
    "    ),\n",
    "    (\n",
    "        'Jaza Unit Trust Fund', \n",
    "        ['jaza']\n",
    "    ),\n",
    "    (\n",
    "        'Masaru Unit Trust Scheme', \n",
    "        ['masaru']\n",
    "    ),\n",
    "    (\n",
    "        'ADAM Unit Trust Scheme', \n",
    "        ['adam']\n",
    "    ),\n",
    "    (\n",
    "        'KCB Unit Trust Scheme (formerly Natbank Unit Trust Scheme)', \n",
    "        ['kcb', 'natbank']\n",
    "    ),\n",
    "    (\n",
    "        'GenAfrica Unit Trust Scheme', \n",
    "        ['genafrica']\n",
    "    ),\n",
    "    (\n",
    "        'Amaka Unit Trust (Umbrella) Scheme', \n",
    "        ['amaka']\n",
    "    ),\n",
    "    (\n",
    "        'Jubilee Unit Trust Collective Investment Scheme', \n",
    "        ['jubilee']\n",
    "    ),\n",
    "    # Previusly \"Liberty Pension Services Limited\"\n",
    "    # https://enwealth.co.ke/about/#governance\n",
    "    # https://www.linkedin.com/company/enwealth-kenya/?originalSubdomain=ke\n",
    "    # https://enwealth.co.ke/capital/enwealth-money-market-fund/\n",
    "    (\n",
    "        'Enwealth Capital Unit Trust Scheme', \n",
    "        ['enwealth']\n",
    "    ),\n",
    "    (\n",
    "        'Kuza Asset Management Unit Trust Scheme', \n",
    "        ['kuza', 'momentum']\n",
    "    ),\n",
    "    # https://www.linkedin.com/company/arvocap-asset-managers/\n",
    "    # https://www.businessdailyafrica.com/bd/markets/avocarp-latest-to-enter-kenya-s-asset-management-market-4644586\n",
    "    (\n",
    "        'Arvocap Unit Trust Scheme', \n",
    "        ['arvocap']\n",
    "    ),\n",
    "    (\n",
    "        'Etica Capital Limited', \n",
    "        ['etica']\n",
    "    ),\n",
    "    # https://licensees.cma.or.ke/licenses/15/\n",
    "    (\n",
    "        'Mayfair umbrella Collective investment scheme', \n",
    "        ['mayfair']\n",
    "    ),\n",
    "    (\n",
    "        'Lofty Corban Unit Trust Scheme', \n",
    "        ['lofty-corban', 'lofty', 'corban']\n",
    "    ),\n",
    "    (\n",
    "        'CPF Unit Trust Funds', \n",
    "        ['cpf', 'cpof']\n",
    "    ),\n",
    "    (\n",
    "        'Stanbic Unit Trust Funds', \n",
    "        ['stanbic']\n",
    "    ),\n",
    "    (\n",
    "        'MyXENO Unit Trust Scheme',\n",
    "        ['myxeno']\n",
    "    ),\n",
    "    #############################################\n",
    "    ##### UNVERIFIED COLLECTIVE INVESTMENTS #####\n",
    "    #############################################\n",
    "    (\n",
    "        'Metropolitan Canon Asset Managers Limited',\n",
    "        ['metropolitan']\n",
    "    ),\n",
    "    (\n",
    "        'FCB Capital Limited',\n",
    "        ['fcb']\n",
    "    ),\n",
    "    (\n",
    "        'Fusion Investment Management Limited',\n",
    "        ['fusion']\n",
    "    ),\n",
    "    (\n",
    "        'Altree Capital Kenya Limited',\n",
    "        ['altree']\n",
    "    ),\n",
    "    (\n",
    "        'CFS Asset Management Limited',\n",
    "        ['cfs']\n",
    "    ),\n",
    "    (\n",
    "        'I&M Capital Limited',\n",
    "        ['i&m']\n",
    "    ),\n",
    "    (\n",
    "        'Globetec Asset Managers Limited',\n",
    "        ['globetec']\n",
    "    ),\n",
    "    (\n",
    "        'Waanzilishi Capital Limited',\n",
    "        ['waanzilishi']\n",
    "    ),\n",
    "    (\n",
    "        'Star Capital Management Limited',\n",
    "        ['star']\n",
    "    ),\n",
    "    # Unverified and NO online presense!\n",
    "    (\n",
    "        'Stanlib Kenya',\n",
    "        ['stanlib']\n",
    "    ),\n",
    "    \n",
    "]\n",
    "SCHEME_NAME_ALIAS_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheme_filter(value: str) -> list[str]:\n",
    "    value = value.lower()\n",
    "    names = [\n",
    "        name \n",
    "        for name, aliases\n",
    "        in SCHEME_NAME_ALIAS_MAP if any((alias.lower() in value) for alias in aliases)\n",
    "    ]\n",
    "    return names\n",
    "\n",
    "# Test\n",
    "def TEST_scheme_filter(fund_manager: str):\n",
    "    name = scheme_filter(fund_manager)\n",
    "    print(f\"{fund_manager} => {name}\")\n",
    "TEST_scheme_filter('KCB Fund Managers')\n",
    "TEST_scheme_filter('Cytonn Fund Mangers')\n",
    "TEST_scheme_filter('Nabo')\n",
    "TEST_scheme_filter('madison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One report can more than one table, see: <https://cytonnreport.com/research/unit-trust-fund-performance-q3-1>. The list below contains a tuple of:\n",
    "1. A list if table names in the records. For matching, the table names are normalized with the below function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_compare_two_strs(str1: str, str2:str) -> bool:\n",
    "    if not str1 or not str2:\n",
    "        return False\n",
    "    str1 = str1.strip().upper()\n",
    "    str2 = str2.strip().upper()\n",
    "    return str1 == str2 or hacky_normalizer(str1) == hacky_normalizer(str2)\n",
    "\n",
    "# Test\n",
    "def TEST_normalize_and_match_two_strs():\n",
    "    str1_str2 = [\n",
    "        ('q2’2020-aum(kshs-mns)', 'Q2 2020_AUM(KSHs_MNs)'),\n",
    "        ('q2’2020-aum(kshs-mns)', \"Q2_2020_AUM(KSHs_MNs)\"),\n",
    "        ('', \"\"),\n",
    "        (None, None),\n",
    "        ('no.', 'NO.')\n",
    "    ]\n",
    "    for str1, str2 in str1_str2:\n",
    "        is_match = normalize_and_compare_two_strs(str1, str2)\n",
    "        print(f'IS_MATCH={is_match}; {[str1, str2]}')\n",
    "\n",
    "TEST_normalize_and_match_two_strs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A list of functions that process the matched tables. Each function should essentially process a single column. The function receives two parameters: a dataframe row data (a table row entry), and the entire record from which the table was extracted from. This first parameter is useful to capture the entry value, and the second is important to capture the date of the record if not provided in the table. The table row entry values are a dictionally named with the table names used to match the tables. <br/> Callback function returns a `RecordEntry`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One report can more than one table, see: <https://cytonnreport.com/research/unit-trust-fund-performance-q3-1> and <https://cytonnreport.com/research/fy2019-utf-performance>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_KSH_MNS = lambda str1: re.sub(r'(?:_AUM)?_?\\(KSHS?_MNS?\\)', '', str1, flags=re.IGNORECASE)\n",
    "remove_MONEY_MARKET_FUND_KSHS_MNS = lambda str1: re.sub(r'_?MONEY_MARKET_FUNDS?_?\\(KSHS?_MNS?\\)', '', str1, flags=re.IGNORECASE)\n",
    "remove_EFFECTIVE_ANNUAL = lambda str1: re.sub(r'_AVERAGE_EFFECTIVE_ANNUAL_YIELD_P_A_|EFFECTIVE_ANNUAL_RATE_|AVERAGE_|\\(|\\)', '', str1, flags=re.IGNORECASE) \n",
    "remove_MONEY_MARKET_FUND_KSHS_MNS_2= lambda str1: re.sub(r'_?MONEY_MARKET_FUNDS?_AUM_?\\(KSHS?_MNS?\\)|_?MONEY_MARKET_FUNDS?_?\\(KSHS?_MNS?\\)', '', str1, flags=re.IGNORECASE)\n",
    "EXTRACTION_MAP: list[\n",
    "    tuple[\n",
    "        list[str], \n",
    "        list[Callable[[dict[str, Any], dict[CYTONN_RECORD_LITERALS, Any]], Extracted_Scheme_Entry]]\n",
    "    ]] = [\n",
    "    (\n",
    "        [\n",
    "            'RANK', \n",
    "            'FUND_MANAGER', \n",
    "            'DAILY_YIELD', \n",
    "            'EFFECTIVE_ANNUAL_RATE'\n",
    "        ], \n",
    "        [\n",
    "            # Effective Annual Rate and Daily Yield\n",
    "            # https://cytonnreport.com/research/cytonn-monthly-october-2021\n",
    "            # https://cytonnreport.com/research/potential-effects-covid-19\n",
    "            lambda row, record: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                record['researchdate'], \n",
    "                row['EFFECTIVE_ANNUAL_RATE'], \n",
    "                row['FUND_MANAGER'],\n",
    "                scheme_filter),\n",
    "            lambda row, record: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                record['researchdate'], \n",
    "                row['DAILY_YIELD'], \n",
    "                row['FUND_MANAGER'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: normalized in ['RANK', hacky_normalizer('NO.')]\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'SCHEME',\n",
    "                'predicate': lambda normalized: bool(re.match(r'MONEY_MARKET_FUNDS?|FUND_MANAGER', normalized))\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'EFFECTIVE_ANNUAL',\n",
    "                'predicate': lambda normalized: normalized in ['EFFECTIVE_ANNUAL', 'EFFECTIVE_ANNUAL_RATE']\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/kenyas-fy2024-2025-budget\n",
    "            # https://cytonnreport.com/research/nairobi-metropolitan-area-serviced-apartments-report-2021\n",
    "            # https://cytonnreport.com/research/cytonn-monthly-may-2024\n",
    "            # https://cytonnreport.com/research/q12023-unit-trust-funds-performance-cytonn-monthly-july-2023\n",
    "            # https://cytonnreport.com/research/investing-in-unit\n",
    "            lambda row, record: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                record['researchdate'], \n",
    "                row['EFFECTIVE_ANNUAL'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter)\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: normalized in ['RANK', hacky_normalizer('NO.')]\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'SCHEME',\n",
    "                'predicate': lambda normalized: bool(re.match(r'MONEY_MARKET_FUNDS?|FUND_MANAGER', normalized))\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'EFFECTIVE_ANNUAL',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_EFFECTIVE_ANNUAL(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: remove_EFFECTIVE_ANNUAL(normalized)\n",
    "                }\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/unit-trust-fund-performance-q3-1\n",
    "            # https://cytonnreport.com/research/fy2019-utf-performance\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                other_params['DATE_1'], \n",
    "                row['EFFECTIVE_ANNUAL'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter)\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                'column_name': 'SCHEME',\n",
    "                'predicate': lambda normalized: 'AVERAGE' in normalized,\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_1_EAR',\n",
    "                'predicate': lambda normalized: bool(re.match(r\"^\\d{4}$\", normalized)),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: normalized.strip()\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_EAR',\n",
    "                'predicate': lambda normalized: bool(re.search(parse_date_pattern, normalized)),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: re.search(parse_date_pattern, normalized).group().replace('_', ' ')\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_3_EAR',\n",
    "                'predicate': lambda normalized: bool(re.search(parse_date_pattern, normalized)),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_3': lambda normalized: re.search(parse_date_pattern, normalized).group().replace('_', ' ')\n",
    "                }\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/cmmf-fact-sheet-june-2020\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                other_params['DATE_1'], \n",
    "                row['DATE_1_EAR'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_2_EAR'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE, \n",
    "                other_params['DATE_3'], \n",
    "                row['DATE_3_EAR'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            'NO.', \n",
    "            'UNIT_TRUST_FUND_MANAGER', \n",
    "            'AUM', \n",
    "            '%_OF_MARKET_SHARE'\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/investment-options-in-kenyan-market\n",
    "            lambda row, record: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                record['researchdate'], \n",
    "                row['AUM'], \n",
    "                row['UNIT_TRUST_FUND_MANAGER'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            'NO.',\n",
    "            'FUND_MANAGERS',\n",
    "            {\n",
    "                'column_name': 'DATE_1_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(normalized.replace('_AUM(KSHS_MNS)', ''))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: normalized.replace('_AUM(KSHS_MNS)', '')\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: 'MARKET_SHARE' in normalized\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(normalized.replace('_AUM(KSHS_MNS)', ''))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: normalized.replace('_AUM(KSHS_MNS)', '')\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_2',\n",
    "                'predicate': lambda normalized: 'MARKET_SHARE' in normalized\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_3',\n",
    "                'predicate': lambda normalized: 'AUM_GROWTH' in normalized\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/unit-trust-funds-performance-q2-2020\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'], \n",
    "                row['DATE_1_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_2_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            'NO.',\n",
    "            'FUND_MANAGERS',\n",
    "            {\n",
    "                'column_name': 'DATE_1_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_MONEY_MARKET_FUND_KSHS_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: remove_MONEY_MARKET_FUND_KSHS_MNS(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_MONEY_MARKET_FUND_KSHS_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: remove_MONEY_MARKET_FUND_KSHS_MNS(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: '_MARKET_SHARE' in normalized\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_2',\n",
    "                'predicate': lambda normalized: '_MARKET_SHARE' in normalized,\n",
    "                'optional': True\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_3',\n",
    "                'predicate': lambda normalized: 'VARIANCE' in normalized,\n",
    "                'optional': True\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/fy2019-utf-performance\n",
    "            # https://cytonnreport.com/research/investing-in-unit\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'], \n",
    "                row['DATE_1_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_2_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            'NO.',\n",
    "            {\n",
    "                'column_name': 'SCHEME',\n",
    "                'predicate': lambda normalized: normalized in ['FUND_MANAGERS', 'FUND_MANAGER']\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_1_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_KSH_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: remove_KSH_MNS(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_KSH_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: remove_KSH_MNS(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: 'GROWTH' in normalized\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/unit-trust-funds-perfomance-q1-2020-cytonn-weekly\n",
    "            # https://cytonnreport.com/research/unit-trust-funds-performance\n",
    "            # https://cytonnreport.com/research/fy2019-utf-performance\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_1_AUM'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_2_AUM'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: bool(normalized in [hacky_normalizer('#'), hacky_normalizer('NO.')])\n",
    "            },\n",
    "            'FUND_MANAGERS',\n",
    "            {\n",
    "                'column_name': 'DATE_1_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_3_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_3': lambda normalized: remove_MONEY_MARKET_FUND_KSHS_MNS_2(normalized)\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_2',\n",
    "                'predicate': lambda normalized: bool('ANNUALIZED' in normalized)\n",
    "            },\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/options-for-your-pension\n",
    "            # https://cytonnreport.com/research/cytonn-monthly-august-2019\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'],\n",
    "                row['DATE_1_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'],\n",
    "                row['DATE_2_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'],\n",
    "                row['DATE_3_AUM'], \n",
    "                row['FUND_MANAGERS'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                'column_name': 'UNWANTED_1',\n",
    "                'predicate': lambda normalized: 'NO' in normalized,\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'SCHEME',\n",
    "                'predicate': lambda normalized: normalized in ['COLLECTIVE_INVESTMENT_SCHEMES', 'FUND_MANAGERS']\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_1_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_KSH_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_1': lambda normalized: remove_KSH_MNS(normalized)\n",
    "                }\n",
    "\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_2',\n",
    "                'predicate': lambda normalized: bool(\n",
    "                    parse_fiscal_period_dates(normalized.replace('MARKET_SHARE', ''))),\n",
    "\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'DATE_2_AUM',\n",
    "                'predicate': lambda normalized: bool(parse_fiscal_period_dates(remove_KSH_MNS(normalized))),\n",
    "                'other_params': \n",
    "                {\n",
    "                    'DATE_2': lambda normalized: remove_KSH_MNS(normalized)\n",
    "                }\n",
    "\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_3',\n",
    "                'predicate': lambda normalized: bool(\n",
    "                    parse_fiscal_period_dates(normalized.replace('MARKET_SHARE', ''))),\n",
    "\n",
    "            },\n",
    "            {\n",
    "                'column_name': 'UNWANTED_4',\n",
    "                'predicate': lambda normalized: 'AUM_GROWTH' in normalized,\n",
    "            }\n",
    "        ], \n",
    "        [\n",
    "            # https://cytonnreport.com/research/unit-trust-fund-performance-q3-1\n",
    "            # https://cytonnreport.com/research/unit-trust-funds-performance-cytonn-monthly-july-2022\n",
    "            lambda row, _, other_params : Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_1'], \n",
    "                row['DATE_1_AUM'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "            lambda row, _, other_params: Extracted_Scheme_Entry(\n",
    "                Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT, \n",
    "                other_params['DATE_2'], \n",
    "                row['DATE_2_AUM'], \n",
    "                row['SCHEME'],\n",
    "                scheme_filter),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_table_and_given_column_names(\n",
    "        given_table_columns, \n",
    "        header_column_names, \n",
    "        *, \n",
    "        use_optional_columns = True):\n",
    "    table_columns = [\n",
    "        table_column \n",
    "        for table_column \n",
    "        in given_table_columns \n",
    "        if type(table_column) == str \n",
    "            or use_optional_columns \n",
    "            or not table_column.get('optional', False)\n",
    "    ]\n",
    "    table_column_strs = [\n",
    "        table_column if type(table_column) == str else table_column['column_name']\n",
    "        for table_column \n",
    "        in table_columns\n",
    "    ]\n",
    "    is_match_new = len(header_column_names) == len(table_columns) and \\\n",
    "        all([\n",
    "                normalize_and_compare_two_strs(header_column_name, table_column) \n",
    "                    if type(table_column) == str \n",
    "                    else table_column['predicate'](hacky_normalizer(header_column_name))\n",
    "                for header_column_name, table_column \n",
    "                in zip(header_column_names, table_columns)\n",
    "            ])\n",
    "    if is_match_new or not use_optional_columns:\n",
    "        other_params = {\n",
    "            other_param_key: other_param_value(hacky_normalizer(header_column_name))\n",
    "            for header_column_name, table_column \n",
    "            in zip(header_column_names, table_columns)\n",
    "            if type(table_column) != str and table_column.get('other_params', None)\n",
    "            for other_param_key, other_param_value\n",
    "            in table_column['other_params'].items()\n",
    "        } if is_match_new else { }\n",
    "        return is_match_new, table_column_strs, other_params\n",
    "    return compare_table_and_given_column_names(\n",
    "        given_table_columns, \n",
    "        header_column_names, \n",
    "        use_optional_columns = False)\n",
    "\n",
    "def get_table(table: Tag, extraction_map):\n",
    "    for tag in table.find_all(True):\n",
    "        tag.attrs = {} # remove tags such as colspan and rowspan\n",
    "    # Iterate through predefined extraction mappings\n",
    "    for (given_table_columns, extractor_callbacks) in extraction_map:\n",
    "        clean_up_tasks: list[Callable[[], None]] = []\n",
    "        header_tr_s: list[Tag] = table.select('thead tr')\n",
    "        is_match = False\n",
    "        is_match_columns = []\n",
    "        is_match_other_params = {}\n",
    "        # Check if table headers match the expected columns\n",
    "        for header_tr in header_tr_s:\n",
    "            header_column_names: list[str] = [i.get_text(strip=True) for i in header_tr.find_all('td')]\n",
    "            is_match_new, pure_str_columns, other_params = compare_table_and_given_column_names(\n",
    "                given_table_columns, \n",
    "                header_column_names)\n",
    "            if is_match_new:\n",
    "                is_match_columns = pure_str_columns\n",
    "                is_match_other_params = other_params or {}\n",
    "            # If not a match, add to cleanup tasks.\n",
    "            # We add cleap tasks here to delay deleting the table headers before we decide \n",
    "            # that this table is matched. When the given columns are matched, the other columns\n",
    "            # are deleted to ensure the dataframe has one column.\n",
    "            if not is_match_new:\n",
    "                clean_up_tasks.append(header_tr.extract)\n",
    "            is_match = is_match or is_match_new\n",
    "        # If a match is found, process the table\n",
    "        if is_match:\n",
    "            try:\n",
    "                # Execute cleanup tasks\n",
    "                [clean_up_task() for clean_up_task in clean_up_tasks]\n",
    "                # Convert table to DataFrame\n",
    "                table_df = pd.read_html(io.StringIO(str(table)))[0]\n",
    "                table_df.columns = is_match_columns\n",
    "                return (table_df, extractor_callbacks, is_match_other_params)\n",
    "            except Exception as e:\n",
    "                print('error', e, table)\n",
    "                continue\n",
    "    return (None, None, None)\n",
    "\n",
    "def is_valid_dataframe(df: pd.DataFrame | None) -> bool:\n",
    "    return df is not None and not df.empty\n",
    "\n",
    "DEBUG_OPTIONS = dict[\n",
    "    Literal[\n",
    "        'log_unmatched_table', \n",
    "        'log_invalid_columns', \n",
    "        'log_extracted_valid',\n",
    "        'log_extracted_invalid',\n",
    "        'log_extractor_count',\n",
    "    ], \n",
    "    Callable[[str], None]\n",
    "]\n",
    "\n",
    "def get_tables(html: str, extraction_map, *, debug_options: DEBUG_OPTIONS = {}):\n",
    "    log_unmatched_table = debug_options.get('log_unmatched_table')\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    parsed_html = BeautifulSoup(html, \"html.parser\")\n",
    "    # Find all <table> elements in the parsed HTML and store them in a list\n",
    "    # remove duplicates\n",
    "    tables: list[Tag] = list({ hacky_normalizer(str(table)): table for table in parsed_html.find_all('table')}.values())\n",
    "    # Iterate over each table found in the HTML\n",
    "    for table in tables:\n",
    "        # Generate a DataFrame and a list of extractor callbacks for each table\n",
    "        table_df, extractor_callbacks, other_params = get_table(copy(table), extraction_map)\n",
    "        # Check if the DataFrame is valid and not None\n",
    "        if is_valid_dataframe(table_df) and table_df is not None:\n",
    "            # Yield the DataFrame and the associated callbacks\n",
    "            yield (table_df, extractor_callbacks, other_params)\n",
    "        else:\n",
    "            if log_unmatched_table:\n",
    "                log_unmatched_table(str(table))\n",
    "\n",
    "def extract_frame_by_column_names(\n",
    "        report: dict[CYTONN_RECORD_LITERALS, str], \n",
    "        tables_html: str,\n",
    "        extraction_map,\n",
    "        *, \n",
    "        debug_options: DEBUG_OPTIONS = {},\n",
    "        ):\n",
    "    log_invalid_columns = debug_options.get('log_invalid_columns')\n",
    "    log_extractor_count = debug_options.get('log_extractor_count')\n",
    "    log_extracted_valid = debug_options.get('log_extracted_valid')\n",
    "    log_extracted_invalid = debug_options.get('log_extracted_invalid')\n",
    "    # Generate tables and callbacks using the get_tables function\n",
    "    table__callback__generator = get_tables(tables_html, extraction_map, debug_options=debug_options)\n",
    "    # Iterate over each table DataFrame and its extractor callbacks\n",
    "    for table_df, extractor_callbacks, other_params in table__callback__generator:\n",
    "        if log_extractor_count:\n",
    "            log_extractor_count(len(extractor_callbacks))\n",
    "        if len(extractor_callbacks) > 0:\n",
    "            # Apply each callback function to the rows of the table\n",
    "            for extractor_callback in extractor_callbacks:\n",
    "                table_rows = [\n",
    "                    dynamic_callback(extractor_callback, raw_table_row.to_dict(), report, other_params)\n",
    "                    for _, raw_table_row \n",
    "                    in table_df.iterrows()\n",
    "                ]\n",
    "                # Convert the processed rows into a new DataFrame\n",
    "                extracted_df = pd.DataFrame([vars(i) for i in table_rows if i.is_valid()])\n",
    "                # Check if the extracted DataFrame is valid and yield it\n",
    "                if is_valid_dataframe(extracted_df):\n",
    "                    if log_invalid_columns:\n",
    "                        __invalid_columns = [vars(i) for i in table_rows if not i.is_valid()]\n",
    "                        if len(__invalid_columns) > 0:\n",
    "                            log_invalid_columns(pd.DataFrame(__invalid_columns))\n",
    "                    if log_extracted_valid:\n",
    "                        log_extracted_valid(extracted_df)\n",
    "                    yield extracted_df\n",
    "                elif log_extracted_invalid:\n",
    "                    log_extracted_invalid(table_df)\n",
    "\n",
    "def extract_table_by_column_names(\n",
    "        report: dict[CYTONN_RECORD_LITERALS, str], \n",
    "        *, \n",
    "        debug_options: DEBUG_OPTIONS = {}):\n",
    "    # Get the HTML content of the report\n",
    "    report_html = get_report_HTML(report)\n",
    "    yield from extract_frame_by_column_names(\n",
    "        report,\n",
    "        report_html, \n",
    "        EXTRACTION_MAP,\n",
    "        debug_options = debug_options)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code extracts and parses entries from all the records and stores various metrics for validating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 651/651 [05:40<00:00,  1.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_type</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_value</th>\n",
       "      <th>entry_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>18.2</td>\n",
       "      <td>Cytonn Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>18.1</td>\n",
       "      <td>Lofty Corban Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>17.4</td>\n",
       "      <td>Etica Capital Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>17.1</td>\n",
       "      <td>Arvocap Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>16.9</td>\n",
       "      <td>Kuza Asset Management Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>[2018-01-01, 2018-12-31]</td>\n",
       "      <td>11.5</td>\n",
       "      <td>Cytonn Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>[2018-01-01, 2018-12-31]</td>\n",
       "      <td>10.2</td>\n",
       "      <td>Nabo Africa Funds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>[2018-01-01, 2018-12-31]</td>\n",
       "      <td>10.1</td>\n",
       "      <td>CIC Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>[2018-01-01, 2018-12-31]</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Madison Unit Trust Fund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>[2018-01-01, 2018-12-31]</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Zimele Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4829 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entry_type                entry_date  entry_value  \\\n",
       "0     EFFECTIVE_ANNUAL_RATE                2024-09-29         18.2   \n",
       "1     EFFECTIVE_ANNUAL_RATE                2024-09-29         18.1   \n",
       "2     EFFECTIVE_ANNUAL_RATE                2024-09-29         17.4   \n",
       "3     EFFECTIVE_ANNUAL_RATE                2024-09-29         17.1   \n",
       "4     EFFECTIVE_ANNUAL_RATE                2024-09-29         16.9   \n",
       "...                     ...                       ...          ...   \n",
       "4824  EFFECTIVE_ANNUAL_RATE  [2018-01-01, 2018-12-31]         11.5   \n",
       "4825  EFFECTIVE_ANNUAL_RATE  [2018-01-01, 2018-12-31]         10.2   \n",
       "4826  EFFECTIVE_ANNUAL_RATE  [2018-01-01, 2018-12-31]         10.1   \n",
       "4827  EFFECTIVE_ANNUAL_RATE  [2018-01-01, 2018-12-31]          9.9   \n",
       "4828  EFFECTIVE_ANNUAL_RATE  [2018-01-01, 2018-12-31]          9.9   \n",
       "\n",
       "                                 entry_scheme  \n",
       "0                    Cytonn Unit Trust Scheme  \n",
       "1              Lofty Corban Unit Trust Scheme  \n",
       "2                       Etica Capital Limited  \n",
       "3                   Arvocap Unit Trust Scheme  \n",
       "4     Kuza Asset Management Unit Trust Scheme  \n",
       "...                                       ...  \n",
       "4824                 Cytonn Unit Trust Scheme  \n",
       "4825                        Nabo Africa Funds  \n",
       "4826                    CIC Unit Trust Scheme  \n",
       "4827                  Madison Unit Trust Fund  \n",
       "4828                 Zimele Unit Trust Scheme  \n",
       "\n",
       "[4829 rows x 4 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stores a tuple of the index of the record, the key for the log and the value logged\n",
    "debug_log_store: list[tuple[str, str, Any]] = []\n",
    "def extract_all_records():\n",
    "    for index, report in tqdm(all_cytonn_reports_df.iterrows(), total=len(all_cytonn_reports_df)):\n",
    "        debug_options = {\n",
    "            'log_unmatched_table': \n",
    "                lambda value_str: debug_log_store.append((index, 'log_unmatched_table', value_str)),\n",
    "            'log_invalid_columns': \n",
    "                lambda value_df: debug_log_store.append((index, 'log_invalid_columns', value_df)),\n",
    "            'log_extracted_valid': \n",
    "                lambda value_tuple_df: debug_log_store.append((index, 'log_extracted_valid', value_tuple_df)),\n",
    "            'log_extracted_invalid': \n",
    "                lambda value_tuple_df: debug_log_store.append((index, 'log_extracted_invalid', value_tuple_df)),\n",
    "            'log_extractor_count': \n",
    "                lambda value_int: debug_log_store.append((index, 'log_extractor_count', value_int)),\n",
    "        }\n",
    "        yield from extract_table_by_column_names(report, debug_options = debug_options)\n",
    "\n",
    "extracted_records_df = pd.concat(objs = extract_all_records(), ignore_index = True)\n",
    "\n",
    "extracted_records_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating Extraction Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 0, 97)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(Extracted_Scheme_Entry.INVALID_SCHEMES), \n",
    "len(Extracted_Scheme_Entry.INVALID_DATES), \n",
    "len(Extracted_Scheme_Entry.INVALID_VALUES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Absa Money Market Fund USD', 'Average',\n",
       "       'Average of Top 5 Money Market Funds',\n",
       "       'Benchmark ( Average 91 day T- Bill + 1.0% point)',\n",
       "       'Benchmark (Average 182 day T- Bill + 5.0% points)',\n",
       "       'CIC Dollar Fund', 'Cytonn Money Market Fund USD',\n",
       "       'Dry Associates Money Market Fund USD', 'Industrial Average',\n",
       "       'Industry average', 'KCB Money Market Fund USD',\n",
       "       'Kuza Money Market Fund USD', 'Lofty-Corban Money Market Fund USD',\n",
       "       'Nabo Africa Money Market Fund USD',\n",
       "       'Old Mutual Dollar Money Market Fund', 'Sanlam Dollar Fund',\n",
       "       'Total', 'Weighted Average Growth', 'nan'], dtype='<U49')"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Extracted_Scheme_Entry.INVALID_SCHEMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(\n",
    "    re.match(r\".*(total|usd|average|dollar).*|nan\", str(i), flags=re.IGNORECASE) \n",
    "    for i \n",
    "    in Extracted_Scheme_Entry.INVALID_SCHEMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-']"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Extracted_Scheme_Entry.INVALID_VALUES).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if every extractor callback was able to extract a table. We'll do this by comparing the number of extracted tables and the number of extractor callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_key_id = groupby(lambda x: (x[0], x[1]), debug_log_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_extractor_count_and_extracted_tables(index: int):\n",
    "    extractor_count_log = grouped_by_key_id.get((index, 'log_extractor_count'))\n",
    "    if extractor_count_log is None:\n",
    "        return True\n",
    "    extractor_count = extractor_count_log[0][2]\n",
    "    extracted_count = len(grouped_by_key_id.get((index, 'log_extracted_valid'), []))\n",
    "    return len(extractor_count_log) == 1 and extracted_count >= extractor_count\n",
    "\n",
    "under_extracted_reports = [\n",
    "    i \n",
    "    for i \n",
    "    in range(len(all_cytonn_reports)) \n",
    "    if not compare_extractor_count_and_extracted_tables(i)\n",
    "]\n",
    "under_extracted_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cytonn_reports_df.iloc[under_extracted_reports]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_why_less_extracted(index):\n",
    "    extracted_valid = grouped_by_key_id.get((index, 'log_extracted_valid'), [])\n",
    "    extracted_invalid = grouped_by_key_id.get((index, 'log_extracted_invalid'), [])\n",
    "    print(f'extracted_valid_count={len(extracted_valid)}, extracted_invalid_count={len(extracted_invalid)}')\n",
    "    return { \n",
    "        'extracted_valid': extracted_valid, \n",
    "        'extracted_invalid': extracted_invalid, \n",
    "        'extracted_valid_df1': extracted_valid[0][2] if extracted_valid else \"No dataframe\", \n",
    "        'extracted_invalid_df1': extracted_invalid[0][2] if extracted_invalid else \"No dataframe\", \n",
    "    }\n",
    "\n",
    "check_why_less_extracted(38)['extracted_invalid_df1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37 has unextracted table because it is in USD money Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html(io.StringIO(grouped_by_key_id.get((293, 'log_unmatched_table'), [])[1][2]))[0]\n",
    "# all_cytonn_reports_df.iloc[293]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at unmatched tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_exclude_names = [\n",
    "    'bank', 'insurance', 'pension', 'Equities', 'Balance', 'ratios', 'Supermarket',\n",
    "    'Budget', 'NSSF', 'Bamburi', 'Metropolitan', 'Land', 'REIT', 'Debt', 'Demand', \n",
    "    'Retail', 'Sahara', 'USD', 'Residential', 'Apartment', 'Credit', 'Hospitality', \n",
    "    'Thematic', 'Company', 'Commercial', 'Office', 'Business', 'Macro', 'Affordable',\n",
    "    'Housing', 'Government', 'Industry', 'NPL', 'GDP', 'Urban', 'Nairobi', 'County',\n",
    "    'Inflation', 'Commodity', 'Price', 'Academia', 'School', 'Fixed Income', 'EPS Growth',\n",
    "    'Rental', 'Life Assurance', 'Loan', 'Education', 'Energy', 'Tourism', 'Restaurant',\n",
    "    'Building', 'Estates', 'Kuramo', 'communications@cytonn.com', 'Fitch Rating', \n",
    "    'Minority', 'Europe', 'Geothermal', 'Tanzania', 'Uganda', 'Occupancy', 'Savings Account', \n",
    "    'Filimbi', 'Undisclosed', 'Sharehold', 'Foreign Direct Investment', 'IEBC', \n",
    "    'Key Performance Indicator', 'hotels', 'Cytonn High Yield Fund', 'years old', 'West Africa'\n",
    "]\n",
    "def table_has_extractable_schemes(tables_str_value: str):\n",
    "    table_tag = BeautifulSoup(tables_str_value, \"html.parser\")\n",
    "    tbody = str(table_tag.find('tbody')).lower()\n",
    "    thead = str(table_tag.find('thead')).lower()\n",
    "    exclude_names = [i.lower() for i in filter_exclude_names]\n",
    "    if not any(i in thead or i in tbody for i in exclude_names):\n",
    "        for _, aliases in SCHEME_NAME_ALIAS_MAP:\n",
    "            for alias in aliases:\n",
    "                if alias.lower() in tbody:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "unmatched_tables = [\n",
    "    (index, table)\n",
    "    for (index, key), tables \n",
    "        in tqdm(grouped_by_key_id.items())\n",
    "        if key == 'log_unmatched_table' \n",
    "    for (_,_,table) \n",
    "        in tables\n",
    "        if table_has_extractable_schemes(table)\n",
    "]\n",
    "len(unmatched_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_table_iterator_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_table_index, unmatched_table_html = unmatched_tables[unmatched_table_iterator_index]\n",
    "unmatched_record = all_cytonn_reports_df.loc[unmatched_table_index, :]\n",
    "print(\n",
    "    f\"{unmatched_table_iterator_index + 1}/{len(unmatched_tables)};\\\n",
    "    DATE: {unmatched_record['researchdate']};\\\n",
    "    URL: {unmatched_record['url']}\")\n",
    "unmatched_table_iterator_index += 1 if unmatched_table_iterator_index < len(unmatched_tables) - 1 else 0\n",
    "unmatched_table_df = pd.read_html(io.StringIO(unmatched_table_html))[0]\n",
    "unmatched_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_extraction_map = [\n",
    "    \n",
    "]\n",
    "\n",
    "new_tables = extract_frame_by_column_names(\n",
    "    unmatched_record, \n",
    "    unmatched_table_html,\n",
    "    new_extraction_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(new_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fiscal_period_dates('2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_column(df: pd.DataFrame, expand_column: str):\n",
    "    for _, row in df.iterrows():\n",
    "        expanding_values = row[expand_column]\n",
    "        if type(expanding_values) in [list, tuple] :\n",
    "            start_date = datetime.strptime(expanding_values[0], \"%Y-%m-%d\")\n",
    "            end_date = datetime.strptime(expanding_values[1], \"%Y-%m-%d\")\n",
    "            start_end_diff_days = (end_date - start_date).days\n",
    "            day_list = [\n",
    "                (start_date + timedelta(days=i)).strftime('%Y-%m-%d') \n",
    "                for i \n",
    "                in range(start_end_diff_days + 1)\n",
    "            ]\n",
    "            for day in day_list:\n",
    "                yield { **row.to_dict(), expand_column: day }\n",
    "        else:\n",
    "            yield row.to_dict()\n",
    "\n",
    "expanded_records_df = pd.DataFrame(expand_date_column(extracted_records_df, 'entry_date'))\n",
    "expanded_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = expanded_records_df.groupby(\n",
    "    ['entry_type', 'entry_date', 'entry_scheme'])['entry_value'].mean().reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAR_df = grouped_df[\n",
    "    grouped_df['entry_type'] == Extracted_Scheme_Entry.TYPE_EFFECTIVE_ANNUAL_RATE\n",
    "    ].drop(columns=['entry_type']).copy()\n",
    "EAR_df['entry_date'] = pd.to_datetime(EAR_df['entry_date'])\n",
    "EAR_pivot = EAR_df.pivot(index='entry_date', columns='entry_scheme', values='entry_value')\n",
    "EAR_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAR_fig = px.line(EAR_pivot, x=EAR_pivot.index, y=EAR_pivot.columns)\n",
    "EAR_fig.update_layout(\n",
    "    height=800,\n",
    "    margin=dict(t=100),\n",
    "    title=dict(\n",
    "        text=\"Effective Annual Rate\",  # Your title here\n",
    "        y=0.98,                   # Adjust the title's vertical position\n",
    "        x=0.5,                    # Center the title\n",
    "        xanchor='center',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        side=\"top\",    # This moves the x-axis to the top\n",
    "        title=\"Date\"   # This sets the title for the x-axis\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Effective Annual Rate\"   # This sets the title for the x-axis\n",
    "    ),\n",
    "\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal orientation\n",
    "        yanchor=\"bottom\",\n",
    "        y=-4.5,  # move the legend below the plot\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ))\n",
    "EAR_fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"fund_manager=%{fullData.name}\",\n",
    "        \"date=%{x|%Y-%m-%d}\",\n",
    "        \"annual_rate=%{y}%\",\n",
    "        # removes any additional trace information that Plotly might add by default.\n",
    "        \"<extra></extra>\"\n",
    "    ])\n",
    ")\n",
    "EAR_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUM_df = grouped_df[\n",
    "    grouped_df['entry_type'] == Extracted_Scheme_Entry.TYPE_ASSETS_UNDER_MANAGEMENT\n",
    "    ].drop(columns=['entry_type']).copy()\n",
    "AUM_df['entry_date'] = pd.to_datetime(AUM_df['entry_date'])\n",
    "AUM_pivot = AUM_df.pivot(index='entry_date', columns='entry_scheme', values='entry_value')\n",
    "AUM_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUM_fig = px.line(AUM_pivot, x=AUM_pivot.index, y=AUM_pivot.columns)\n",
    "AUM_fig.update_layout(\n",
    "    height=800,\n",
    "    margin=dict(t=100),\n",
    "    title=dict(\n",
    "        text=\"Assets Under Management\",  # Your title here\n",
    "        y=0.98,                   # Adjust the title's vertical position\n",
    "        x=0.5,                    # Center the title\n",
    "        xanchor='center',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        side=\"top\",    # This moves the x-axis to the top\n",
    "        title=\"Date\"   # This sets the title for the x-axis\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Assets Under Management\"   # This sets the title for the x-axis\n",
    "    ),\n",
    "\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # horizontal orientation\n",
    "        yanchor=\"bottom\",\n",
    "        y=-4.5,  # move the legend below the plot\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ))\n",
    "AUM_fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"fund_manager=%{fullData.name}\",\n",
    "        \"date=%{x|%Y-%m-%d}\",\n",
    "        \"annual_rate=%{y}%\",\n",
    "        # removes any additional trace information that Plotly might add by default.\n",
    "        \"<extra></extra>\"\n",
    "    ])\n",
    ")\n",
    "AUM_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achrives\n",
    "\n",
    "To ensure perpetuity and reproducibility of this analysis, the crawled [Cytton Reports](https://huggingface.co/datasets/ToKnow-ai/money-market-funds-in-kenya__july-2024-archive/viewer/cytonn_reports) and [Capital Markets Authority Approved Fund Managers](https://huggingface.co/datasets/ToKnow-ai/money-market-funds-in-kenya__july-2024-archive/viewer/cma_approved_fund_managers) has been archived at <https://huggingface.co/datasets/ToKnow-ai/money-market-funds-in-kenya__july-2024-archive>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error uploading dataset: (Request ID: Root=1-66fdd930-09f486ee5bdee7a216b4af1a;a47d44de-2647-4654-a14a-3cc725fbd7b8)\n",
      "\n",
      "403 Forbidden: You don't have the rights to create a dataset under the namespace \"toknow-ai\".\n",
      "Cannot access content at: https://huggingface.co/api/repos/create.\n",
      "Make sure your token has the correct permissions.\n",
      "Error uploading dataset: (Request ID: Root=1-66fdd931-1d808dc7440841555746de0c;1f63d2fd-3d9d-4c70-bd43-47ad3f49003c)\n",
      "\n",
      "403 Forbidden: You don't have the rights to create a dataset under the namespace \"toknow-ai\".\n",
      "Cannot access content at: https://huggingface.co/api/repos/create.\n",
      "Make sure your token has the correct permissions.\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "(\"Expected bytes, got a 'list' object\", 'Conversion failed for column entry_date with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[683], line 20\u001b[0m\n\u001b[1;32m      8\u001b[0m upload_dataframe_to_huggingface(\n\u001b[1;32m      9\u001b[0m     collective_schemes_df, \n\u001b[1;32m     10\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id, \n\u001b[1;32m     11\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApproved Collective Investment Schemes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     12\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m upload_dataframe_to_huggingface(\n\u001b[1;32m     15\u001b[0m     all_cytonn_reports_df, \n\u001b[1;32m     16\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id, \n\u001b[1;32m     17\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw Cytonn Reports\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     18\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mupload_dataframe_to_huggingface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_records_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessed Unit Trust Records\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/python_utils/upload_dataset.py:21\u001b[0m, in \u001b[0;36mupload_dataframe_to_huggingface\u001b[0;34m(df, repo_id, dataset_name, split, private, preserve_index)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mUpload a pandas DataFrame to a Hugging Face dataset.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Convert DataFrame to Hugging Face Dataset\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m hf_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Initialize Hugging Face API\u001b[39;00m\n\u001b[1;32m     24\u001b[0m api \u001b[38;5;241m=\u001b[39m HfApi()\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:838\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    836\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    837\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 838\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/datasets/table.py:719\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    665\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/table.pxi:4623\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:629\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 629\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:603\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    599\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    600\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    601\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    607\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:597\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    594\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    599\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    600\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    601\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/array.pxi:358\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: (\"Expected bytes, got a 'list' object\", 'Conversion failed for column entry_date with type object')"
     ]
    }
   ],
   "source": [
    "#|output: false\n",
    "#|echo: false\n",
    "\n",
    "from python_utils.upload_dataset import upload_dataframe_to_huggingface, login\n",
    "\n",
    "repo_id = \"toknow-ai/collective-investment-schemes-in-kenya-analysis-dataset\"\n",
    "\n",
    "upload_dataframe_to_huggingface(\n",
    "    collective_schemes_df, \n",
    "    repo_id=repo_id, \n",
    "    dataset_name=\"Approved Collective Investment Schemes\", \n",
    "    split=\"data\")\n",
    "\n",
    "upload_dataframe_to_huggingface(\n",
    "    all_cytonn_reports_df, \n",
    "    repo_id=repo_id, \n",
    "    dataset_name=\"Raw Cytonn Reports\", \n",
    "    split=\"data\")\n",
    "\n",
    "upload_dataframe_to_huggingface(\n",
    "    extracted_records_df, \n",
    "    repo_id=repo_id, \n",
    "    dataset_name=\"Processed Unit Trust Records\", \n",
    "    split=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "(\"Expected bytes, got a 'list' object\", 'Conversion failed for column entry_date with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[693], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 3\u001b[0m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_records_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/datasets/arrow_dataset.py:838\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    836\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[1;32m    837\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[0;32m--> 838\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/datasets/table.py:719\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    665\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/table.pxi:4623\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:629\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 629\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:603\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    599\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    600\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    601\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    607\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/pandas_compat.py:597\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    594\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    599\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    600\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    601\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/array.pxi:358\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/toknow.ai/.env/lib/python3.10/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: (\"Expected bytes, got a 'list' object\", 'Conversion failed for column entry_date with type object')"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "Dataset.from_pandas(extracted_records_df, preserve_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_type</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>entry_value</th>\n",
       "      <th>entry_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>9.2</td>\n",
       "      <td>British-American Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>15.6</td>\n",
       "      <td>Cytonn Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>15.5</td>\n",
       "      <td>Etica Capital Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>15.4</td>\n",
       "      <td>GenAfrica Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-12-03</td>\n",
       "      <td>15.1</td>\n",
       "      <td>Lofty Corban Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Cytonn Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Lofty Corban Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>12.2</td>\n",
       "      <td>GenAfrica Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>11.9</td>\n",
       "      <td>ICEA Unit Trust Scheme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>EFFECTIVE_ANNUAL_RATE</td>\n",
       "      <td>2023-08-13</td>\n",
       "      <td>11.8</td>\n",
       "      <td>Madison Unit Trust Fund</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 entry_type  entry_date  entry_value  \\\n",
       "1100  EFFECTIVE_ANNUAL_RATE  2023-12-10          9.2   \n",
       "1101  EFFECTIVE_ANNUAL_RATE  2023-12-03         15.6   \n",
       "1102  EFFECTIVE_ANNUAL_RATE  2023-12-03         15.5   \n",
       "1103  EFFECTIVE_ANNUAL_RATE  2023-12-03         15.4   \n",
       "1104  EFFECTIVE_ANNUAL_RATE  2023-12-03         15.1   \n",
       "...                     ...         ...          ...   \n",
       "1495  EFFECTIVE_ANNUAL_RATE  2023-08-13         12.4   \n",
       "1496  EFFECTIVE_ANNUAL_RATE  2023-08-13         12.4   \n",
       "1497  EFFECTIVE_ANNUAL_RATE  2023-08-13         12.2   \n",
       "1498  EFFECTIVE_ANNUAL_RATE  2023-08-13         11.9   \n",
       "1499  EFFECTIVE_ANNUAL_RATE  2023-08-13         11.8   \n",
       "\n",
       "                            entry_scheme  \n",
       "1100  British-American Unit Trust Scheme  \n",
       "1101            Cytonn Unit Trust Scheme  \n",
       "1102               Etica Capital Limited  \n",
       "1103         GenAfrica Unit Trust Scheme  \n",
       "1104      Lofty Corban Unit Trust Scheme  \n",
       "...                                  ...  \n",
       "1495            Cytonn Unit Trust Scheme  \n",
       "1496      Lofty Corban Unit Trust Scheme  \n",
       "1497         GenAfrica Unit Trust Scheme  \n",
       "1498              ICEA Unit Trust Scheme  \n",
       "1499             Madison Unit Trust Fund  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_records_df[1100:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #| .content-visible when-format: \"html\" -->\n",
    "\n",
    "### CMA Approved Fund Managers\n",
    "\n",
    "{{< iframe \n",
    "  'Loading Approved Fund Managers...' \n",
    "  src=\"https://huggingface.co/datasets/ToKnow-ai/unit-trust-investments-in-kenya-money-market-funds/embed/viewer/C.M.A%20Approved%20Fund%20Managers/data\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"560px\" >}}\n",
    "\n",
    "### Detailed CMA Approved Fund Managers\n",
    "{{< iframe \n",
    "  'Loading Approved Fund Managers...' \n",
    "  src=\"https://huggingface.co/datasets/ToKnow-ai/unit-trust-investments-in-kenya-money-market-funds/embed/viewer/Detailed%20C.M.A%20Approved%20Fund%20Managers/data\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"560px\" >}}\n",
    "\n",
    "### Cytonn Reports\n",
    "\n",
    "{{< iframe \n",
    "  'Loading Cytonn Reports...' \n",
    "  src=\"https://huggingface.co/datasets/ToKnow-ai/unit-trust-investments-in-kenya-money-market-funds/embed/viewer/Cytonn%20Reports/data\"\n",
    "  frameborder=\"0\" \n",
    "  width=\"100%\" \n",
    "  height=\"560px\" >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<!-- metadata: abstract, preserve_cell=true -->\n",
    "It seems like good investment. blah blah blah blah blah blah blah blah...\n",
    "<!-- metadata: -->\n",
    "\n",
    "Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important links\n",
    "\n",
    " - https://licensees.cma.or.ke/\n",
    " - https://licensees.cma.or.ke/licenses/15/\n",
    " - https://licensees.cma.or.ke/licenses/8/\n",
    " - https://www.rba.go.ke/registered-fund-managers/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
